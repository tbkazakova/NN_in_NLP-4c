{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdXQYpZNl-jy"
      },
      "source": [
        "Домашнее задание №4.\n",
        "\n",
        "Применение бертоподобных моделей к задаче классификации\n",
        "\n",
        "Решите задачу классификации по тональности на подготовленном в тетрадке корпусе, используя пайплайн с Trainer от HuggingFace.\n",
        "\n",
        "\n",
        "1. обучите ту модель, которую мы разбирали на занятии (класс SentimentClassifier из тетрадки) -- 2 балла\n",
        "\n",
        "2. измените модель, чтобы помимо выхода с пуллер-слоя использовался эмбеддинг cls-токена с последнего слоя. -- 3 балла\n",
        "\n",
        "3. примените к данным готовую модель для классификации последовательности (типа BertForSequenceClassification) -- 2 балла\n",
        "\n",
        "*4. агрегируйте cls-токены для нескольких слоев, чтобы сделать предсказание класса -- 2 дополнительных балла\n",
        "\n",
        "5. выберите на сайте google play три понравившихся вам отзыва, относящиеся к разным классам. Покажите, как на них работает любая из обученных моделей -- 2 балла\n",
        "\n",
        "Общие требования: (1 балл) Для всех моделей используйте одинаковые гиперпараметры, чтобы их результаты можно было сравнить между собой.\n",
        "\n",
        "Комментируйте ваши решения в коде.\n",
        "\n",
        "Для каждой из моделей нужно привести результаты на тестовой выборке.\n",
        "\n",
        "Вы можете использовать любую предобученную модель, которая подходит для работы с английским, кроме bert-base-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "# 1. Модель, которую мы разбирали на занятии\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xs_m3fW8Ux3"
      },
      "source": [
        "Наша сегодняшняя задача - классификация отзывов.\n",
        "Данные - отзывы на приложения в Google Play, классы:  negative (1,2), neutral (3), positive (4,5) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnMnfH86v9OZ"
      },
      "source": [
        "Мы будем использовать библиотеку [Transformers](https://huggingface.co/transformers/) от Hugging Face "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjsbi1u3QFEM",
        "outputId": "61cb5d06-15de-4e12-ffc7-00f9f9c3edea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (2.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJqoaFpVpoM8",
        "outputId": "f2841dad-0f9a-44d5-947e-a4f63ac07c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.13\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.21.5\n",
            "pandas      : 1.3.5\n",
            "torch       : 1.10.0+cu111\n",
            "transformers: 4.17.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcsWUODBwScb"
      },
      "source": [
        "Загрузим набор данных, который мы будем использовать для обучения и тестирования модели -- отзывы на приложения в Google Play.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgPRhuMzi9ot",
        "outputId": "595b6a71-91bd-496b-c49b-270a33d5b3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 67.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "100% 7.17M/7.17M [00:00<00:00, 104MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z1jvVHb6CaW-"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, DistilBertModel, AutoTokenizer, BertTokenizer, DistilBertTokenizerFast, AdamW, get_linear_schedule_with_warmup, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "co9bB2BPWiA6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 8, 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mUKLyKc7I6Qp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upsJBG-h1EkX",
        "outputId": "661b9029-dbe4-4135-e47e-5612e2f4881a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df = df[:6000]  # чтоб быстрее было\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_wGSLQLKCh",
        "outputId": "1d5ee7c5-312e-4c92-d7ca-fa315dedba58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   userName              6000 non-null   object\n",
            " 1   userImage             6000 non-null   object\n",
            " 2   content               6000 non-null   object\n",
            " 3   score                 6000 non-null   int64 \n",
            " 4   thumbsUpCount         6000 non-null   int64 \n",
            " 5   reviewCreatedVersion  5026 non-null   object\n",
            " 6   at                    6000 non-null   object\n",
            " 7   replyContent          3121 non-null   object\n",
            " 8   repliedAt             3121 non-null   object\n",
            " 9   sortOrder             6000 non-null   object\n",
            " 10  appId                 6000 non-null   object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 515.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I6M1dS5AiMuY"
      },
      "outputs": [],
      "source": [
        "from google.colab import data_table\n",
        "data_table.disable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "r8oY_X-euY6e",
        "outputId": "4b62d412-7067-4f1d-dfa1-4edfd6bb7719"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           userName                                          userImage  \\\n",
              "0     Andrew Thomas  https://lh3.googleusercontent.com/a-/AOh14GiHd...   \n",
              "1      Craig Haines  https://lh3.googleusercontent.com/-hoe0kwSJgPQ...   \n",
              "2     steven adkins  https://lh3.googleusercontent.com/a-/AOh14GiXw...   \n",
              "3  Lars Panzerbjørn  https://lh3.googleusercontent.com/a-/AOh14Gg-h...   \n",
              "4     Scott Prewitt  https://lh3.googleusercontent.com/-K-X1-YsVd6U...   \n",
              "\n",
              "                                             content  score  thumbsUpCount  \\\n",
              "0  Update: After getting a response from the deve...      1             21   \n",
              "1  Used it for a fair amount of time without any ...      1             11   \n",
              "2  Your app sucks now!!!!! Used to be good but no...      1             17   \n",
              "3  It seems OK, but very basic. Recurring tasks n...      1            192   \n",
              "4  Absolutely worthless. This app runs a prohibit...      1             42   \n",
              "\n",
              "  reviewCreatedVersion                   at  \\\n",
              "0             4.17.0.3  2020-04-05 22:25:57   \n",
              "1             4.17.0.3  2020-04-04 13:40:01   \n",
              "2             4.17.0.3  2020-04-01 16:18:13   \n",
              "3             4.17.0.2  2020-03-12 08:17:34   \n",
              "4             4.17.0.2  2020-03-14 17:41:01   \n",
              "\n",
              "                                        replyContent            repliedAt  \\\n",
              "0  According to our TOS, and the term you have ag...  2020-04-05 15:10:24   \n",
              "1  It sounds like you logged in with a different ...  2020-04-05 15:11:35   \n",
              "2  This sounds odd! We are not aware of any issue...  2020-04-02 16:05:56   \n",
              "3  We do offer this option as part of the Advance...  2020-03-15 06:20:13   \n",
              "4  We're sorry you feel this way! 90% of the app ...  2020-03-15 23:45:51   \n",
              "\n",
              "       sortOrder      appId  \n",
              "0  most_relevant  com.anydo  \n",
              "1  most_relevant  com.anydo  \n",
              "2  most_relevant  com.anydo  \n",
              "3  most_relevant  com.anydo  \n",
              "4  most_relevant  com.anydo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e36aad3-561c-4f49-9412-bd4e8817f0f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e36aad3-561c-4f49-9412-bd4e8817f0f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e36aad3-561c-4f49-9412-bd4e8817f0f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e36aad3-561c-4f49-9412-bd4e8817f0f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPqoVTjJwpDF"
      },
      "source": [
        "Посмотрим на распределение классов в выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Wwh_rW4Efhs3",
        "outputId": "b4ba86b5-904e-49ec-da9a-9f25f97b962c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 521,
              "height": 381
            }
          }
        }
      ],
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdDtjvRsw9PT"
      },
      "source": [
        "Можно видеть, что данные несбалансированы. \n",
        "Теперь приведем метки классов к другому виду -- разделим их на 3 класса: негативные, нейтральные и позитивные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "outputs": [],
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "outputs": [],
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "y3tY3ECJDPaz",
        "outputId": "4195fda1-ff6d-4c60-8e0a-c3371c2e5677"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBMAAAL6CAYAAABkXR4tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfXBV9Z3H8c/Nc8hzIITyEAUFJLdAFFZEKPIQZpZ0IgW3NNGFVRJQrA9V2zFspRXbLXZnaNkVY22iQeqCtdYsoIO1BFDAUEsghCEQpQQJD8YbSIx5vpfc/YPJ3Vxyb5IT7kkgvF8zzJx7f7/f9/wOzJwhn5zz+1mcTqdTAAAAAAAA3eTX1xMAAAAAAADXF8IEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABgS0NcTwLWrtLRUzc3N8vf3V3BwcF9PBwAAAADgQ83Nzbp06ZKCg4OVmJhoaCxhArxqbm5Wa2urWltbZbfb+3o6AAAAAAATNDc3Gx5DmACv/P391draKj8/Pw0YMKCvpwMAAAAA8KGGhga1trbK39/f8FjCBHgVHBwsu92uAQMGaOzYsX09HQAAAACAD5WVlamurq5Hr7WzACMAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYEtDXEzBDc3Oz9uzZo71796qkpEQVFRVqaGhQeHi4Ro8erdmzZ2vRokUKDw/vtI7D4dBbb72lbdu2qby8XC0tLRo6dKiSk5P14IMPKjY2tsu5XLx4URs2bNCOHTt07tw5BQUFaeTIkUpNTVVaWpoCArr+JygrK9Mbb7yhwsJCVVVVKSoqSlarVWlpaZo1a1a3/14AAAAAAPAFi9PpdPb1JHztjjvuUH19fad9hgwZopdeekkTJkzw2P7NN98oIyNDhw8f9tgeFxennJwcjRs3zus5SktLtXz5ctlsNo/tSUlJys3NVUREhNca+fn5WrVqlex2u8f29PR0Pf/8817HX42ysjLV1dUpPDxcY8eONeUcAAAAAIC+cTU/8/XL1xzq6+sVGBioefPmae3atfrwww/16aef6r333tPy5csVEBCgL7/8UpmZmaqsrPRY4+mnn9bhw4dlsVj0yCOP6K9//av27NmjNWvWKCIiQjabTQ8//LBqamo8jq+pqdEjjzwim82myMhIrVmzRnv27NFf//pXPfLII7JYLCouLtbTTz/t9TqKior03HPPyW63a8yYMXrttddUWFiod999V8nJyZKkzZs3Kycn5+r/0gAAAAAA6Cb/5836tXYfunjxol5++WXdd999GjNmjKKjoxUSEqKBAwfq7rvvVkJCgj788EM1NzerqalJM2fOdBv/0Ucfaf369ZKkH/3oR3r88ccVFRWlsLAwjRs3TnfccYfy8/NVV1cni8Wiu+++u8McXnrpJe3Zs0cWi0Wvv/665syZo7CwMEVFRWnq1Kny9/fX/v379cUXX2jixIm66aabOtR48skndf78eQ0aNEh/+tOfNHbsWIWGhmrw4MFKSUnRoUOHVFFRoeLiYi1atEihoaE+/Xu8cOGCWlpaFBQUpEGDBvm0NgAAAACgb13Nz3z98smEn//854qLi/PanpqaqjFjxkiSPv744w7tmzZtkiTFxMQoIyOjQ/vkyZNdAcSf/vQnORwOt3aHw6G3335bkjRz5kxNnjy5Q42MjAxFR0e7na+9I0eOqKSkRJKUmZmpmJgYt3aLxaJnnnlGktTQ0KAtW7Z4vV4AAAAAAHypX4YJ3TF69GhJ0ldffeX2fVNTkwoLCyVJc+bMUVBQkMfx8+bNk3T5dYaioiK3tgMHDqi2ttat35WCgoJcryp88sknampqcmvftWtXh3NdyWq1KiEhQZK0c+dOj30AAAAAAPC1GzZMqKqqkqQOix9+/vnnam5ulnR5gURv2rcdPXrUra395+7UaG5u1okTJzzWiI+P15AhQ7zWmDhxosc5AAAAAABglhsyTKiqqtLBgwclSbfffrtbW3l5uet4+PDhXmsMHTpUfn5+Hca0/+zn56ehQ4d6rdG+vrcaI0aM8Dq+fY36+nqvi0kCAAAAAOBLN2SYsHbtWtdWi+np6W5t1dXVruOBAwd6rREYGKjIyEhJ6rCjQ1uNyMhIBQYGeq0RGxvrOvZWo7M5XNnubWcJAAAAAAB8KaCvJ9Dbtm7dqnfffVeSNHv2bH3nO99xa29sbHQdBwcHd1qrrb2hocFjja7Gh4SEuI691fC2ZkN3avhKXV1dh3UhzDRp0qReOxcA3+rNe0Vf4j4FXL9uhPsU9yjg+nU93aNuqCcTSkpKtGrVKknSt771Lf3Hf/xHH88IAAAAAIDrzw3zZMLJkye1fPlyNTU1KTo6Wrm5uW6vGbQJDQ11HbctxOhNW/uAAQM81uhqfPsdHDzVsNvtamlp6XENXwkPD9fYsWNNqd2ZUfnlXXcCcE04uWCkpBvvt2GnCkf29RQAdNPNUy//v+JGuk+d+jn3KOB6cfPqvrlHlZWVqa6urkdjb4gnE86dO6elS5equrpaYWFhysnJ0a233uqxb0xMjOv4woULXmva7XbX9o/R0dEea9TW1srhcHitcfHiRdextxqdzeHK9itrAAAAAABghn4fJlRVVemhhx7S+fPnFRISot/97neaMGGC1/4jR/5/gnvmzBmv/c6dO6fW1tYOY9p/bm1t1dmzZ73WaF/fW42Kigqv49vXCAsLU3x8fKd9AQAAAADwhX4dJnz99dd66KGHdOrUKQUGBuq///u/deedd3Y6ZvTo0a6FEw8fPuy1X3FxsevYarW6tbX/3J0awcHBHZ6UaKtRWVnZ6ZaPbfWvnAMAAAAAAGbpt2FCfX29MjMz9dlnn8nPz0//+Z//qXvuuafLcSEhIZo6daokqaCgwOuaBR988IGky68WXPley+TJk13bRrb1u1JLS4t27twpSbr77rvddmWQpFmzZrmOt2/f7rFGaWmpTp8+LenyzhQAAAAAAPSGfhkmtLS0aMWKFSopKZEkvfDCC0pJSen2+Pvvv1/S5TUN8vLyOrQXFRVp9+7dkqTvf//7CghwX8cyICBAixYtkiTt2rXL4/YeeXl5rjUT2s7X3vjx412vY+Tm5qqmpsat3el0au3atZIuL7w4f/78bl8fAAAAAABXo9+FCZcuXdKPfvQj/e1vf5MkPfHEE0pJSVF9fb3XP06n063GPffcoxkzZkiS1q1bp3Xr1qmiokI2m035+flasWKFWltbFR8fr8zMTI/zWLZsmeLj49Xa2qoVK1YoPz9fNptNFRUV+u1vf6t169ZJkmbMmOE615WysrIUEBAgm82mxYsXa9++fbp48aKOHTumJ554Qnv37pUkPfroox53pgAAAAAAwAwW55U/SV/nzpw5ozlz5hgaU1BQoOHDh7t9V1tbq8zMTK9rHsTFxSknJ0fjxo3zWre0tFTLly+XzWbz2J6UlKTc3FxFRER4rZGfn69Vq1bJbrd7bE9LS9Pq1au9jr8abduEsDUkgK60bQ15o2FrSOD60bY15I2ErSGB60fb1pC97Wp+5gvousuNKTIyUps2bdJbb72lrVu3qry8XHa7XUOHDtWcOXP00EMPdfk0QGJiorZu3aq8vDwVFBTo3LlzCgwM1KhRo5Samqq0tLQOr0hcacGCBUpMTNSGDRu0f/9+2Ww2RUVFyWq1Kj093W1tBQAAAAAAekO/ezIBvsOTCQC6iycTAFzreDIBwLXsenwyod+tmQAAAAAAAMxFmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGBLQ1xMwg9Pp1MmTJ1VSUuL6U1ZWJrvdLkkqKCjQ8OHDPY49c+aM5syZY+h8Gzdu1JQpU9y+y8rKUn5+fpdjH3jgAf3sZz/rtE9ZWZneeOMNFRYWqqqqSlFRUbJarUpLS9OsWbMMzRUAAAAAgKvVL8OEs2fPKiUlpVfOFRAQoFtuucW0+vn5+Vq1apUrCJEkm82m3bt3a/fu3UpPT9fzzz9v2vkBAAAAALhSvwwT2hsyZIjGjx+v6upqHThwoMv+w4YN08GDBzvtU1tbq7lz58put2vatGkaNGiQ176TJk1STk6O1/bAwECvbUVFRXruuefkcDg0ZswYPfvss0pMTNT58+eVnZ2tHTt2aPPmzRo2bJiWLVvW5bUBAAAAAOAL/TJMiI6O1ssvv6yJEycqLi5OkvTSSy91K0ywWCwKCwvrtM+WLVtcTwp873vf67Svv79/l/W8efHFF+VwODRo0CBt3LhRMTExkqTY2FitX79eGRkZ2rdvn7Kzs3XfffcpNja2R+cBAAAAAMCIfrkAY3h4uJKTk11Bgq9t2bJFkhQREWF4fYXuOnLkiEpKSiRJmZmZriChjcVi0TPPPCNJamhocM0JAAAAAACz9cswwUxffPGFiouLJUnz5s1TcHCwKefZtWuX63jevHke+1itViUkJEiSdu7caco8AAAAAAC4EmGCQf/7v//rOp4/f363x126dEmXLl3qdv+jR49KkuLj4zVkyBCv/SZOnOjWHwAAAAAAs/XLNRPM4nQ6tXXrVknSiBEjNHny5C7HfPbZZ5o7d67OnDkjp9Op6OhoJSUlaeHChZo7d64sFovHceXl5a7zdKZti8v6+npVVlYqPj7eyCUBAAAAAGAYTyYYcODAAZ05c0ZS1wsvtqmpqdHp06fV2toqp9Op6upq7dq1S48//rgyMjL09ddfexxXXV0tSRo4cGCn9du319TUdGtOAAAAAABcDZ5MMKDtFQeLxdLlKw6DBg1SZmamvvOd72jEiBGKi4tTXV2dDh48qFdffVUlJSXat2+ffvjDH2rjxo3y83PPdRobGyVJQUFBnZ4nJCTEddzQ0NCTy+pSXV2dioqKTKntyaRJk3rtXAB8qzfvFX2J+xRw/boR7lPco4Dr1/V0jyJM6Kbm5mb95S9/kSTdcccdXb5+8OMf/7jDd7GxsUpOTtbMmTP11FNP6cMPP9Tf//53bd26tdtPOgAAAAAA0NcIE7qpoKBA33zzjaTuv+LgTUBAgF544QXt2bNHjY2N2rZtW4eaoaGhstvtamlp6bRWU1OT63jAgAFXNS9vwsPDNXbsWFNqA+hf+G0YgGsd9ykA17LevkeVlZWprq6uR2NZM6Gb2l5xCA4O9rpVoxExMTG6/fbbJUmlpaUe2yXpwoULndZp3x4dHX3V8wIAAAAAoCuECd1QVVWlffv2SZLmzJmjiIgIn9SNjY2VJNcTD+2NHDlSklRRUdFpjbYFIcPCwtjJAQAAAADQKwgTuuG9996Tw+GQdPWvOLRXVVUlSR7DCavVKkmqrKxUZWWl1xqHDx926w8AAAAAgNkIE7phy5Ytki7v0DB9+nSf1Lxw4YIOHTokSUpMTOzQPmvWLNfx9u3bPdYoLS3V6dOnJUmzZ8/2ybwAAAAAAOgKYUIXPv/8c9eaBqmpqfL39+9yjM1m06VLl7y2t7S06Kc//amam5slSffee2+HPuPHj9eECRMkSbm5uaqpqXFrdzqdWrt2raTLCy92tVUlAAAAAAC+0m93czhx4oTbqpRffvml6/jYsWOuVwwkKSEhwbV+wZXy8/Ndx919xeH999/Xm2++qdTUVE2ZMkU333yzwsLCVFtbq6KiIr322ms6fvy4JGnKlClKTU31WCcrK0tLliyRzWbT4sWLlZWVpXHjxqmyslLZ2dnau3evJOnRRx/1On8AAAAAAHyt34YJq1ev1qeffuqx7bHHHnP7vGbNGi1cuLBDv9bWVm3btk2SNHbsWN12223dPn9FRYWys7OVnZ3ttc+cOXP061//Wn5+nh8QmTRpkn75y19q1apV+uyzz7R06dIOfdLS0rRs2bJuzwsAAAAAgKvVb8MEXygsLNRXX30lydjCi3PnzpXT6dShQ4d04sQJVVdXq7a2VsHBwYqPj1dSUpLmz5+vu+66q8taCxYsUGJiojZs2KD9+/fLZrMpKipKVqtV6enpbmsrAAAAAADQGyxOp9PZ15PAtamsrEx1dXUKDw/X2LFje/38o/LLe/2cAHrm5IKRfT2FPnGq8Ma8buB6dPPUG+//Fad+zj0KuF7cvLpv7lFX8zMfCzACAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMC+noCZnA6nTp58qRKSkpcf8rKymS32yVJBQUFGj58uNfx7777rlauXNnleUaPHq333nuv0z4XL17Uhg0btGPHDp07d05BQUEaOXKkUlNTlZaWpoCArv8JysrK9MYbb6iwsFBVVVWKioqS1WpVWlqaZs2a1eV4AAAAAAB8qV+GCWfPnlVKSkpfT0OlpaVavny5bDab67vGxkYVFxeruLhY27ZtU25uriIiIrzWyM/P16pVq1xBiCTZbDbt3r1bu3fvVnp6up5//nkzLwMAAAAAADf9Mkxob8iQIRo/fryqq6t14MABw+MPHjzotc3f399rW01NjR555BHZbDZFRkZq5cqVmj59upqamvTnP/9Zr776qoqLi/X0008rJyfHY42ioiI999xzcjgcGjNmjJ599lklJibq/Pnzys7O1o4dO7R582YNGzZMy5YtM3xtAAAAAAD0RL8ME6Kjo/Xyyy9r4sSJiouLkyS99NJLPQoTwsLCejSHnJwcVVZWymKx6JVXXtHkyZNdbU899ZRCQkK0bt06ffzxx/r44481Y8aMDjVefPFFORwODRo0SBs3blRMTIwkKTY2VuvXr1dGRob27dun7Oxs3XfffYqNje3RXAEAAAAAMKJfLsAYHh6u5ORkV5DQ2xwOh95++21J0syZM92ChDYZGRmKjo6WJG3atKlD+5EjR1RSUiJJyszMdAUJbSwWi5555hlJUkNDg7Zs2eLTawAAAAAAwJt+GSb0tQMHDqi2tlaSNG/ePI99goKClJycLEn65JNP1NTU5Na+a9cu17G3GlarVQkJCZKknTt3XvW8AQAAAADoDsKEbmppael236NHj7qOk5KSvPZra2tubtaJEyc81oiPj9eQIUO81pg4cWKHcwIAAAAAYKZ+uWaCLy1YsECff/657Ha7BgwYoMTERM2dO1eLFi3SgAEDPI4pLy+XJPn5+Wno0KFea7ffnrK8vFzf/va3O9QYMWJEp/Nrq1FfX6/KykrFx8d378IAAAAAAOghnkzoQmlpqWtbxoaGBh04cEBr1qzRvffeq+PHj3scU11dLUmKjIxUYGCg19rtF0ysqanxWGPgwIGdzq99+5U1AAAAAAAwA08meBASEqIFCxYoOTlZt9xyi4YMGaJLly7p+PHj2rRpk95//31VVFQoIyND7777boenARobGyVJwcHBXZ6nTUNDg8caQUFBPa7hK3V1dSoqKjKltieTJk3qtXMB8K3evFf0Je5TwPXrRrhPcY8Crl/X0z2KMMGDlJQUpaSkdPh+8uTJmjx5siZMmKA1a9aoqqpK69at05o1a/pglgAAAAAA9A3ChB548MEH9f7776ukpEQffPCBXnjhBbfXGUJDQyVdXlixM+13cLhy/YXQ0FDZ7fYuF37srIavhIeHa+zYsabUBtC/8NswANc67lMArmW9fY8qKytTXV1dj8ayZkIPzZ49W9LlVwu++OILt7aYmBhJUm1trRwOh9caFy9edB1HR0d7rHHhwoVO59G+/coaAAAAAACYgTChh9ovfFhbW+vWNnLkSElSa2urzp4967XGmTNnOoy58nNFRUWn82irERYWxk4OAAAAAIBeQZjQQzabzXUcGRnp1ma1Wl3Hhw8f9lqjuLhY0uWFGm+99VaPNSorK1VZWem1Rlv99ucEAAAAAMBMhAk9VFBQIOnyEwE33XSTW9vkyZNdAcMHH3zgcXxLS4t27twpSbr77rvddmWQpFmzZrmOt2/f7rFGaWmpTp8+Len/X7sAAAAAAMBshAlXqKur63IBit///vc6evSoJGnevHluiy9KUkBAgBYtWiRJ2rVrl8ftPfLy8lxrJtx///0d2sePH68JEyZIknJzc1VTU+PW7nQ6tXbtWkmXF16cP39+dy4PAAAAAICr1m93czhx4oRbKPDll1+6jo8dO6aqqirX54SEBMXGxkq6vEbBkiVLlJKSohkzZmj06NGKiopSS0uLjh8/rs2bN7ueSoiLi9MTTzzh8fzLli3Ttm3bVFlZqRUrVmjlypWaPn26mpqa9M477+j3v/+9JGnGjBmaMWOGxxpZWVlasmSJbDabFi9erKysLI0bN06VlZXKzs7W3r17JUmPPvqoa/4AAAAAAJjN4nQ6nX09CTMsXrxYn376abf6rlmzRgsXLpR0OWj43ve+1+WYW2+9Vf/1X//VYa2D9kpLS7V8+XK39RXaS0pKUm5uriIiIrzWyM/P16pVq2S32z22p6WlafXq1V3Otyfatgnpq60hR+WX9/o5AfTMyQUju+7UD50qvDGvG7ge3Tz1xvt/xamfc48Crhc3r+6be9TV/MzXb59M6KmEhAT98pe/VHFxsUpLS1VVVaWamhr5+fkpNjZWVqtVycnJSklJUVBQUKe1EhMTtXXrVuXl5amgoEDnzp1TYGCgRo0apdTUVKWlpSkgoPN/ggULFigxMVEbNmzQ/v37ZbPZFBUVJavVqvT0dLe1FQAAAAAA6A399skEXD2eTADQXTyZAOBax5MJAK5l1+OTCSzACAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYEtDXEzCD0+nUyZMnVVJS4vpTVlYmu90uSSooKNDw4cO9jr948aIKCgq0f/9+HTt2TOfPn5fdbldMTIysVqtSU1P1z//8z/L39/daIysrS/n5+V3O9YEHHtDPfvazTvuUlZXpjTfeUGFhoaqqqhQVFSWr1aq0tDTNmjWry3MAAAAAAOBL/TJMOHv2rFJSUno0tqSkROnp6XI4HB3avvrqK3311VfatWuX3nzzTb388suKjY292ul2Kj8/X6tWrXIFIZErcwwAACAASURBVJJks9m0e/du7d69W+np6Xr++edNnQMAAAAAAO31yzChvSFDhmj8+PGqrq7WgQMHuuzf2Ngoh8Oh6OhopaamasaMGRo9erRCQ0N18uRJ5eXl6cMPP9TBgwe1YsUKbd68WX5+3t8WmTRpknJycry2BwYGem0rKirSc889J4fDoTFjxujZZ59VYmKizp8/r+zsbO3YsUObN2/WsGHDtGzZsi6vDQAAAAAAX+iXYUJ0dLRefvllTZw4UXFxcZKkl156qVthQkREhJ599lk98MADCg4Odmu74447dMcdd2jVqlV6++23VVxcrA8++KDTpyD8/f0VFhbWo+t48cUX5XA4NGjQIG3cuFExMTGSpNjYWK1fv14ZGRnat2+fsrOzdd9995n+lAQAAAAAAFI/XYAxPDxcycnJriDBiMTERC1durRDkNDeU0895XoaYc+ePT2eZ2eOHDmikpISSVJmZqYrSGhjsVj0zDPPSJIaGhq0ZcsWU+YBAAAAAMCV+mWYYLbY2FgNHDhQ0uV1FMywa9cu1/G8efM89rFarUpISJAk7dy505R5AAAAAABwJcKEHrDb7fr6668lXX4KojsuXbqkS5cudfscR48elSTFx8dryJAhXvtNnDjRrT8AAAAAAGbrl2smmG337t1qaWmRJN1+++2d9v3ss880d+5cnTlzRk6nU9HR0UpKStLChQs1d+5cWSwWj+PKy8slSSNGjOi0ftsWl/X19aqsrFR8fLzRywEAAAAAwBCeTDCopaVFv/nNbyRJYWFhuvfeezvtX1NTo9OnT6u1tVVOp1PV1dXatWuXHn/8cWVkZLiecLhSdXW1JLlep/CmfXtNTY2RSwEAAAAAoEd4MsGgX/ziFzp58qQk6YknnvC6g8KgQYOUmZmp73znOxoxYoTi4uJUV1engwcP6tVXX1VJSYn27dunH/7wh9q4cWOH7SUbGxslSUFBQZ3OJyQkxHXc0NBwNZfmVV1dnYqKikyp7cmkSZN67VwAfKs37xV9ifsUcP26Ee5T3KOA69f1dI8iTDDgD3/4g95++21J0owZM/Rv//ZvXvv++Mc/7vBdbGyskpOTNXPmTD311FP68MMP9fe//11bt27V9773PdPmDQAAAACALxEmdNP27dv1q1/9SpL07W9/W+vWrfO63kFXAgIC9MILL2jPnj1qbGzUtm3bOoQJoaGhstvtrrUZvGlqanIdDxgwoEfz6Up4eLjGjh1rSm0A/Qu/DQNwreM+BeBa1tv3qLKyMtXV1fVoLGsmdMOePXv0k5/8RK2trRo9erRyc3MVFhZ2VTVjYmJcizeWlpZ6bJekCxcudFqnfXt0dPRVzQkAAAAAgO4gTOjCgQMH9Pjjj8tutyshIUGvv/666wf9q9W23sI333zToW3kyJGSpIqKik5rnDlzRtLlxSDZyQEAAAAA0BsIEzpx9OhRPfzww2psbFR8fLzy8vI0ePBgn9WvqqqSJEVERHRos1qtkqTKykpVVlZ6rXH48GG3/gAAAAAAmI0wwYsTJ04oIyNDdXV1iomJUV5enoYPH+6z+hcuXNChQ4ckSYmJiR3aZ82a5Trevn27xxqlpaU6ffq0JGn27Nk+mxsAAAAAAJ0hTPDgzJkzWrp0qaqrqxUREaHXX39dt9xyS7fH22w2Xbp0yWt7S0uLfvrTn6q5uVmSdO+993boM378eE2YMEGSlJubq5qaGrd2p9OptWvXSrq88OL8+fO7PT8AAAAAAK5Gv93N4cSJE26rUn755Zeu42PHjrleMZCkhIQE1/oFVVVVeuihh1RZWamgoCD95je/0U033aT6+nqP5/Hz81NoaKjbd++//77efPNNpaamasqUKbr55psVFham2tpaFRUV6bXXXtPx48clSVOmTFFqaqrH2llZWVqyZIlsNpsWL16srKwsjRs3TpWVlcrOztbevXslSY8++qhr/gAAAAAAmK3fhgmrV6/Wp59+6rHtsccec/u8Zs0aLVy4UJL08ccfu14daGlp0bJlyzo9z7Bhw7Rz584O31dUVCg7O1vZ2dlex86ZM0e//vWv5efn+QGRSZMm6Ze//KVWrVqlzz77TEuXLu3QJy0trcs5AgAAAADgS/02TOhLc+fOldPp1KFDh3TixAlVV1ertrZWwcHBio+PV1JSkubPn6+77rqry1oLFixQYmKiNmzYoP3798tmsykqKkpWq1Xp6eluaysAAAAAANAbLE6n09nXk8C1qaysTHV1dQoPD9fYsWN7/fyj8st7/ZwAeubkgpF9PYU+carwxrxu4Hp089Qb7/8Vp37OPQq4Xty8um/uUVfzMx8LMAIAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYEmBG0ZUrV8pisehHP/qRBg8e3K0xNptNv/nNb2SxWPSrX/3KjGkBAAAAAAAfMOXJhPz8fOXn56u2trbbY7755hvXOAAAAAAAcO3iNQcAAAAAAGDINRMmOBwOSVJAgClvXgAAAAAAAB+5ZsKEEydOSJKioqL6eCYAAAAAAKAzPnkM4O9//7vH748cOaLq6upOx7a0tOjUqVPKzc2VxWLRbbfd5ospAQAAAAAAk/gkTFi8eLEsFovbd06nU//+7//e7RpOp1MWi0ULFy70xZQAAAAAAIBJfLZAgdPp7NZ33oSGhiojI0MpKSm+mhIAAAAAADCBT8KENWvWuH1euXKlLBaLnnzyScXHx3sdZ7FYFBwcrMGDBysxMVGhoaG+mA4AAAAAADCRT8KEBQsWuH1euXKlJCk5OVm33nqrL04BAAAAAACuEabsw7hx40ZJ0vDhw80oDwAAAAAA+pApYcKdd95pRlkAAAAAAHAN8OvrCQAAAAAAgOuLKU8mtFdTU6Pi4mJVVFSorq5Oly5d6nLMY489Zva0AAAAAABAD5kWJnz99dd68cUX9d5778nhcBgaS5gAAAAAAMC1y5Qwob6+Xv/6r/+qEydOyOl0GhprsVjMmBIAAAAAAPARU8KE119/XZ9//rkk6dZbb9UDDzyg8ePHKyoqSn5+LNMAAAAAAMD1zJQw4cMPP5TFYtGECRO0ceNGBQcHm3EaAAAAAADQB0x5TODMmTOSpMzMTIIEAAAAAAD6GVPChMDAQEnSiBEjzCgPAAAAAAD6kClhwk033SRJunjxohnlAQAAAABAHzIlTEhNTZXT6dTOnTvNKA8AAAAAAPqQKWHC/fffL6vVqj/+8Y/av3+/GacAAAAAAAB9xJQwISAgQDk5ORo/frwyMzP161//WqWlpWpqajLjdAAAAAAAoBeZsjXkuHHjXMdOp1MbNmzQhg0bujXWYrGotLTUjGkBAAAAAAAfMCVMcDqdnX4GAAAAAADXL1PChAULFphRFgAAAAAAXANMCRPWrFljRlkAAAAAAHANMGUBRgAAAAAA0H8RJgAAAAAAAEMIEwAAAAAAgCGmrJlw7ty5qxo/dOhQH80EAAAAAAD4milhwuzZs2WxWHo01mKxqLS01MczAgAAAAAAvmJKmCBJTqfTrNIAAAAAAKAPmRImPPbYY132aWho0MmTJ/XJJ5/IbrcrKSlJ06ZNM2M6AAAAAADAh/osTGhjs9mUlZWl/fv3a+HChfr+979vxpQAAAAAAICP9PluDnFxcXrllVc0atQovfDCCzp27FhfTwkAAAAAAHSiz8MESQoKCtKSJUtkt9u1YcOGvp4OAAAAAADoxDURJkjSbbfdJkn629/+1sczAQAAAAAAnblmwoTW1lZJ0oULF/p4JgAAAAAAoDPXTJjw8ccfS5IiIiL6eCYAAAAAAKAz10SYsGXLFuXk5MhisSgpKamvpwMAAAAAADphytaQK1eu7LKP0+nU119/raNHj8pms8npdMrPz09Lly41Y0oAAAAAAMBHTAkT8vPzZbFYutXX6XRenkhAgH76059q8uTJV31+p9OpkydPqqSkxPWnrKxMdrtdklRQUKDhw4d3WcfhcOitt97Stm3bVF5erpaWFg0dOlTJycl68MEHFRsb22WNixcvasOGDdqxY4fOnTunoKAgjRw5UqmpqUpLS1NAQNf/BGVlZXrjjTdUWFioqqoqRUVFyWq1Ki0tTbNmzer6LwQAAAAAAB8yJUyQ/j8k8MbPz09hYWEaMWKE7rzzTv3gBz/QyJEjfXLus2fPKiUl5apqfPPNN8rIyNDhw4fdvv/HP/6hf/zjH3r33XeVk5OjcePGea1RWlqq5cuXy2azub5rbGxUcXGxiouLtW3bNuXm5na6TkR+fr5WrVrlCkIkyWazaffu3dq9e7fS09P1/PPP9/xCAQAAAAAwyJQw4fjx42aU7ZEhQ4Zo/Pjxqq6u1oEDB7o97umnn9bhw4dlsVj08MMP67777lNISIj27t2rX/3qV7LZbHr44Ye1detWRUdHdxhfU1OjRx55RDabTZGRkVq5cqWmT5+upqYm/fnPf9arr76q4uJiPf3008rJyfE4h6KiIj333HNyOBwaM2aMnn32WSUmJur8+fPKzs7Wjh07tHnzZg0bNkzLli3r8d8RAAAAAABGXBMLMPpadHS0Xn75Ze3du1cfffSR1q9fr7vuuqvb4z/66CPX7hJPPvmknnrqKSUkJGjw4MFauHChfve738lisaiyslK5ubkea+Tk5KiyslIWi0WvvPKKFi5cqMGDByshIUFPPfWUnnzySUmXd7FoO9eVXnzxRTkcDg0aNEgbN27U9OnTFRsbK6vVqvXr12vatGmSpOzsbF28eNHIXxEAAAAAAD3WL8OE8PBwJScnKy4urkfjN23aJEmKiYlRRkZGh/bJkydr5syZkqQ//elPcjgcbu0Oh0Nvv/22JGnmzJke14HIyMhwPdHQdr72jhw5opKSEklSZmamYmJi3NotFoueeeYZSVJDQ4O2bNli5BIBAAAAAOixfhkmXI2mpiYVFhZKkubMmaOgoCCP/ebNmyfp8usMRUVFbm0HDhxQbW2tW78rBQUFKTk5WZL0ySefqKmpya19165dHc51JavVqoSEBEnSzp07O70uAAAAAAB8xbQFGNs4nU7t3LlT+/btU1lZmWpqaiRdfhXhtttu07Rp0zRr1qxu7/5gts8//1zNzc2SpKSkJK/92rcdPXpUU6ZMcfvsqZ+nGu+8846am5t14sQJffvb3+5QIz4+XkOGDPFaY+LEiTp9+rTbOQEAAAAAMJOpYcLBgwe1cuVKnT592vVd2y4PFotFBw8e1KZNm5SQkKAXX3xRt99+u5nT6Zby8nLXcWfbRw4dOlR+fn5qbW11G9O+hp+fn4YOHeq1Rvv65eXlbmFCW40RI0Z0Ot+2GvX19aqsrFR8fHyn/QEAAAAAuFqmvebw0UcfacmSJTp9+rScTqecTqeCg4M1dOhQDR06VCEhIa7vv/jiCy1evFh79uwxazrdVl1d7ToeOHCg136BgYGKjIyUJNfTFlfWiIyMVGBgoNcasbGxrmNvNTqbw5XtV9YAAAAAAMAMpjyZUF1drWeeeUYOh0N+fn76l3/5F6Wnp2vcuHGu1xmcTqeOHTumt956S++8844cDoeefvpp/fWvf/W41WJvaWxsdB0HBwd32retvaGhwWONrsaHhIS4jr3V8LZmQ3dq+EpdXV2HdSHMNGnSpF47FwDf6s17RV/iPgVcv26E+xT3KOD6dT3do0x5MuHNN99UXV2dAgICtH79ev3iF79QYmKi27oIFotFiYmJeuGFF5SdnS1/f3/V1dXpzTffNGNKAAAAAADAR0x5MuGjjz6SxWLRokWLNHv27C77z5w5Uz/4wQ+0adMmffTRR3rsscfMmFa3hIaGuo7bFmL0pq19wIABHmt0Nb79Dg6eatjtdrW0tPS4hq+Eh4dr7NixptQG0L/w2zAA1zruUwCuZb19jyorK1NdXV2PxpryZEJFRYUkae7cud0e09a3/WKNfSEmJsZ1fOHCBa/97Ha7a/vHK1/LaKtRW1srh8PhtcbFixddx95qdDaHK9v78vUQAAAAAMCNw5Qwoe3d/aioqG6PaVvM0Kz3/rtr5MiRruMzZ8547Xfu3Dm1trZ2GNP+c2trq86ePeu1Rvv63mq0BTNd1QgLC2MnBwAAAABArzAlTGj7DfmVWyZ25tSpU5LcnwzoC6NHj3YtnHj48GGv/YqLi13HVqvVra395+7UCA4O1q233uqxRmVlpSorK73WaKt/5RwAAAAAADCLKWGC1WqV0+nU//zP/3R7zJtvvulalLEvhYSEaOrUqZKkgoICr2sWfPDBB5IuBydXvtcyefJk15MWbf2u1NLSop07d0qS7r77brddGSRp1qxZruPt27d7rFFaWup6LaQ7a1MAAAAAAOALpoQJKSkpkqRDhw7pJz/5SaevLjQ2NiorK0uHDh2SJH33u981Y0qG3H///ZIur2mQl5fXob2oqEi7d++WJH3/+99XQID7OpYBAQFatGiRJGnXrl0et/fIy8tzrZnQdr72xo8frwkTJkiScnNzVVNT49budDq1du1aSZcXXpw/f76RSwQAAAAAoMdM2c0hNTVVf/jDH3TkyBG99957Kiws1He/+10lJSUpLi5OkmSz2XT48GG99957rkUEJ0yYoNTUVJ/M4cSJE26rUn755Zeu42PHjqmqqsr1OSEhQbGxsa7P99xzj2bMmKGPP/5Y69atU2Njo+677z6FhIRo7969WrNmjVpbWxUfH6/MzEyP51+2bJm2bdumyspKrVixQitXrtT06dPV1NSkd955R7///e8lSTNmzNCMGTM81sjKytKSJUtks9m0ePFiZWVlady4caqsrFR2drb27t0rSXr00Ufd5g8AAAAAgJksTqfTaUbhCxcu6MEHH9Tnn39++UQWi8d+bacfPXq03njjDZ/9ULx48WJ9+umn3eq7Zs0aLVy40O272tpaZWZmel3zIC4uTjk5ORo3bpzXuqWlpVq+fLlsNpvH9qSkJOXm5ioiIsJrjfz8fK1atUp2u91je1pamlavXu11/NVo2yakr7aGHJXf/TU3APStkwtGdt2pHzpVeGNeN3A9unnqjff/ilM/5x4FXC9uXt0396ir+ZnPlCcTJGngwIF655139Morr+itt97q8Jh+m5iYGKWnp+uRRx5RUFCQWdMxLDIyUps2bdJbb72lrVu3qry8XHa7XUOHDtWcOXP00EMPdRl8JCYmauvWrcrLy1NBQYHOnTunwMBAjRo1SqmpqUpLS+vwisSVFixYoMTERG3YsEH79++XzWZTVFSUrFar0tPT3dZWAAAAAACgN5j2ZEJ7DodDR48e1Weffabq6mpJl0OEsWPHKjExscsfqNE3eDIBQHfxZAKAax1PJgC4lvFkgreTBARo4sSJmjhxYm+cDgAAAAAAmMi0MKFt8cPQ0FD5+/t32vfSpUtqbGyUJIWHh5s1JQAAAAAA4AOmbA356aef6p/+6Z80bdo012sNnamurtbdd9+tO++8U8XFxWZMCQAAAAAA+IgpYcJf/vIXOZ1OzZw5U4MGDeqy/6BBgzRr1iy1trZq+/btZkwJAAAAAAD4iClhwqFDh2SxWDR9+vRuj5kxY4Yk6cCBA2ZMCQAAAAAA+IgpYcLp06clSbfccku3x4waNUqSdObMGTOmBAAAAAAAfMSUMKGpqUmSNGDAgG6PCQ0NlSTV19ebMSUAAAAAAOAjpoQJERERkiSbzdbtMVVVVZKksLAwM6YEAAAAAAB8xJQwISEhQZJUWFjY7TH79u2TJA0bNsyMKQEAAAAAAB8xJUy466675HQ69cc//lHnz5/vsv/Zs2f19ttvy2KxaOrUqWZMCQAAAAAA+IgpYUJaWpoCAgLU0NCghx56SMePH/fa9/jx41q6dKnq6+vl7++vtLQ0M6YEAAAAAAB8JMCMot/61rf0+OOP67e//a2++OILLVy4UFOnTtWUKVM0ePBgSdJXX32lv/3tbyosLJTT6ZTFYtEPf/hDjRgxwowpAQAAAAAAHzElTJCkhx9+WDU1NcrLy5PT6dQnn3yiTz75pEM/p9MpScrIyNCKFSvMmg4AAAAAAPARU15zaPPss8/qtdde0+TJk2WxWOR0Ot3+WCwW3XnnncrLy9NPfvITM6cCAAAAAAB8xLQnE9pMmzZN06ZNU21trUpLS3Xx4kVJUmxsrBITExUZGWn2FAAAAAAAgA+ZHia0iYyM1F133dVbpwMAAAAAACYx9TUHAAAAAADQ/xAmAAAAAAAAQwgT/o+9O4+rskz8//8GARFQAddccpeP0JhOWGlIitSkhkuN5li0uKW2q6XOzOfrjNlgi42t7lo6KmNKBVo6H1FDE3fRSQXNUUQxPIqALLL6+4PfOcORc4CbRTBfz8ejR7f3tZzrxrrO4X2u+7oBAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhjjV9gDqoqCgIF24cKHC9V9++WW98sorlj9HRERo5syZ5bbr0qWLNm7cWGad1NRUffHFF9q6dauSk5Pl4uKiDh06KCQkRKNGjZKTE3+FAAAAAIBbi99Eq0HXrl1rpN/jx49rwoQJMplMlnM5OTmKi4tTXFycoqKitHTpUjVs2LBGXh8AAAAAAFsIE2zYtGmTioqKyqzz9NNP68SJE2rcuLH69+9vt96hQ4fsltWrV89uWVpamiZOnCiTyaRGjRpp5syZCggI0PXr17VhwwYtWrRIcXFxmjJlipYsWVL+RQEAAAAAUE0IE2xo0KBBmeWnT5/WiRMnJEkDBw6Ui4uL3bru7u6VGsOSJUuUkpIiBwcHLViwQP7+/payN954Q66urpo/f75iYmIUExOjwMDASr0OAAAAAABGsQFjJXzzzTeW4+HDh1d7/wUFBVq3bp0kqV+/flZBgtnYsWPl6ekpSVqzZk21jwEAAAAAAHsIEwy6ceOGoqKiJEnt27dXjx49qv01Dhw4oIyMDEnFKx9scXFxUXBwsCRp9+7dun79erWPAwAAAAAAWwgTDNqzZ48uXrwoSRo6dGiF2+Xl5VW47rFjxyzHZYUV5rLc3Fz9/PPPFe4fAAAAAICqYM8Eg7799ltJkoODQ4XChOHDh+vUqVPKz8+Xm5ubfH199cgjj2jkyJFyc3Oz2ebMmTOSJEdHR7Vq1cpu323atLFqc8899xi5FAAAAAAAKoWVCQbk5ORoy5YtkqRevXqpdevW5bY5fvy48vPzJUnZ2dk6cOCAwsLCNGTIEMXHx9tsc/XqVUlSo0aN5OzsbLdvb29vy3FaWlqFrwMAAAAAgKpgZYIB//rXv5SdnS1JGjZsmN16rq6uGj58uIKDg9WpUye1bNlShYWFio+P15o1a7Rp0yYlJSVp7NixioiIUIsWLaza5+TkSJLq169f5nhcXV0tx+Zx1YTMzEwdPHiwxvq/2X333XfLXgtA9bqVc0VtYp4Cbl93wjzFHAXcvm6nOYowwYDIyEhJxY+O/N3vfme33qBBgzRo0KBS5/39/eXv76/u3bsrLCxMly9f1vz58xUWFlZjYwYAAAAAoLoRJlTQpUuXFBsbK0kaMGCAPDw8Kt3X888/r02bNuno0aPavHmzZs+ebXU7Q4MGDSQVb6xYlpJPcLC3/0J18PDwkI+PT431D+DXg2/DANR1zFMA6rJbPUclJCQoMzOzUm3ZM6GCIiMjVVhYKKl4U8WqCgoKklR8e0JiYqJVmZeXlyQpIyNDBQUFdvtITU21HHt6elZ5TAAAAAAAVARhQgWZn+LQvHlz9enTp8r9NWnSxHKckZFhVdahQwdJUlFRkS5cuGC3j/Pnz5dqAwAAAABATSNMqIDjx4/r5MmTkqSQkBA5Olb9x2YymSzHjRo1sirz8/OzHB85csRuH3FxcZKKN2rs3LlzlccEAAAAAEBFECZUgHlVglT2UxyMiI6OliS5u7urXbt2VmX+/v6WgGHz5s022+fl5Wnbtm2SpD59+lg92QEAAAAAgJpEmFCOwsJCbdy4UVLxioGuXbuWWT8zM7PcDSwWL16sY8eOSZIGDhxotfmiJDk5OWnkyJGSpO3bt9t8PMiKFSsseyaMHj26YhcDAAAAAEA14GkO5di1a5cuX74sSRo6dGi59ZOSkvTss89q0KBBCgwMVJcuXdS4cWPl5eUpPj5ea9eutaxKaNasmV599VWb/YwfP15RUVFKSUnRpEmTNHPmTAUEBOj69etav369Fi9eLEkKDAxUYGBgNV0tAAAAAADlI0woxzfffCOpeLVASEhIhdpkZGQoPDxc4eHhdut07txZH330kVq0aGGz3NPTUwsXLtSECRNkMpk0Y8aMUnV69OihDz/8sEJjAgAAAACguhAmlCEzM9OyL0Hfvn3l7e1dbpu7775bc+bMUVxcnI4fP67Lly8rLS1Njo6O8vb2lp+fn4KDgzVo0CC5uLiU2Zevr68i27sq0AAAIABJREFUIyO1YsUKRUdHKzk5Wc7OzurYsaNCQkI0atQoOTnxVwgAAAAAuLX4TbQMHh4eZT5NwRZ3d3eNGDFCI0aMqJYxeHt7a+rUqZo6dWq19AcAAAAAQFWxASMAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYIhTbQ+gLjp//rwGDBhQobqxsbHy9va2WVZQUKDw8HBFRUXpzJkzysvLU6tWrRQcHKznn3/ebruSUlNT9cUXX2jr1q1KTk6Wi4uLOnTooJCQEI0aNUpOTvwVAgAAAABuLX4TrSHXrl3T2LFjdeTIEavzp0+f1unTpxUREaElS5aoW7dudvs4fvy4JkyYIJPJZDmXk5OjuLg4xcXFKSoqSkuXLlXDhg1r7DoAAAAAALgZYUI5Fi9eLH9/f7vl7u7uNs9PmTJFR44ckYODg1588UU9+eSTcnV11a5du/S3v/1NJpNJL774oiIjI+Xp6VmqfVpamiZOnCiTyaRGjRpp5syZCggI0PXr17VhwwYtWrRIcXFxmjJlipYsWVJt1wsAAAAAQHkIE8rh6upqNzCw54cfflBMTIwk6bXXXtOkSZMsZU888YTuvvtuPfPMM0pJSdHSpUs1bdq0Un0sWbJEKSkpcnBw0IIFC6wCjTfeeEOurq6aP3++YmJiFBMTo8DAwEpeIQAAAAAAxrABYw1Ys2aNJMnLy0tjx44tVe7v769+/fpJkr766isVFBRYlRcUFGjdunWSpH79+tlcGTF27FjLigbz6wEAAAAAcCsQJlSz69evKzY2VpI0YMAAubi42Kw3cOBAScW3Mxw8eNCq7MCBA8rIyLCqdzMXFxcFBwdLknbv3q3r169Xy/gBAAAAACgPYUIF5eXlVajeqVOnlJubK0nq0aOH3Xoly44dO2ZVVvLPFekjNzdXP//8c4XGBwAAAABAVbFnQjnefvttXbhwQdnZ2XJxcVH79u3Vt29fPfvss2rZsmWp+mfOnLEct2nTxm6/rVq1kqOjo4qKiqzalOzD0dFRrVq1sttHyf7PnDmje+65p8LXBQAAAABAZbEyoRynTp1Sdna2pOLVCSdPntSyZcs0cOBAbdq0qVT9q1evWo6bNGlit19nZ2c1atRIUvGtDrb6aNSokZydne324e3tbTm+uQ8AAAAAAGoKKxNscHR0VEBAgAYPHiw/Pz/dddddql+/vhITE7Vp0yYtX75c2dnZevPNN9W4cWMFBARY2ubk5FiO69evX+brmMvNYcXNfZTX3tXV1XJ8cx/VKTMzs9S+DjXpvvvuu2WvBaB63cq5ojYxTwG3rzthnmKOAm5ft9McRZhgQ6tWrbRs2bJS57t27aquXbvq4Ycf1vPPP6/c3Fy9/fbb+u6771SvXr1aGCkAAAAAALceYUIl/Pa3v1VoaKiWLl2qs2fP6ujRo+rZs6ckqUGDBpZ65o0Y7TGXu7m5WZ0391Fe+5JPcLi5j+rk4eEhHx+fGusfwK8H34YBqOuYpwDUZbd6jkpISFBmZmal2rJnQiUFBQVZjo8fP2459vLyshxfuXLFbvv8/HzL4x89PT2tysx9ZGRkqKCgwG4fqampluOb+wAAAAAAoKYQJlRSyc0Vr127Zjnu0KGD5fj8+fN22ycnJ6uoqKhUm5J/Lioq0oULF+z2UbL/m/sAAAAAAKCmECZU0uXLly3HDRs2tBx36dLFsnHikSNH7LaPi4uzHPv5+VmVlfxzRfqoX7++OnfuXMGRAwAAAABQNYQJlfR///d/luOSv/y7urqqd+/ekqTo6Gjl5eXZbL9582ZJxbcn3HxfjL+/v+WxkeZ6N8vLy9O2bdskSX369LF6sgMAAAAAADWJMMGGX375pczyvXv3as2aNZKk9u3bq3v37lblo0ePllS8p8GKFStKtT948KB27NghSRoxYoScnKz3wXRyctLIkSMlSdu3b7f5eJAVK1ZY9kwwvx4AAAAAALcCT3OwYdiwYerVq5cGDBggPz8/NW3aVJKUlJSkTZs2afXq1crPz5eTk5P+3//7f3J0tM5kHn74YQUGBiomJkbz589XTk6OnnzySbm6umrXrl0KCwtTUVGRWrRooXHjxtkcw/jx4xUVFaWUlBRNmjRJM2fOVEBAgK5fv67169dr8eLFkqTAwEAFBgbW7A8EAAAAAIASHG7cuHGjtgdR1/j7+1ttqmhL48aN9c477+iRRx6xWZ6RkaFx48bZ3fOgWbNmWrJkibp162b3NY4fP64JEybIZDLZLO/Ro4eWLl1qtWdDdTI/JqS2Hg3Z8eszt/w1AVTOf4bfmZvAno29M68buB21733nfa44O4s5CrhdtP9r7cxRVfmdj5UJNoSFhenAgQM6cuSIUlJSlJaWpvz8fDVu3FidO3dWQECAfv/731s9BvJmjRo10po1axQeHq7IyEidOXNG+fn5atWqlQYMGKAXXnhB3t7eZY7D19dXkZGRWrFihaKjo5WcnCxnZ2d17NhRISEhGjVqVKlbJAAAAAAAqGmsTIBdrEwAUFGsTABQ17EyAUBddjuuTGADRgAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgiFNtD6Cuys3N1c6dO7Vr1y4dPXpUSUlJys7OloeHh7p06aKgoCCNHDlSHh4eNttHRERo5syZ5b5Oly5dtHHjxjLrpKam6osvvtDWrVuVnJwsFxcXdejQQSEhIRo1apScnPhrBAAAAADcOvwWakfv3r2VlZVV6nxaWpr279+v/fv368svv9Qnn3yi7t2719g4jh8/rgkTJshkMlnO5eTkKC4uTnFxcYqKitLSpUvVsGHDGhsDAAAAAAAlESbYkZWVJWdnZwUHBys4OFi/+c1v5OnpqUuXLikyMlLLly/XL7/8onHjxikqKkotWrSw29ehQ4fsltWrV89uWVpamiZOnCiTyaRGjRpp5syZCggI0PXr17VhwwYtWrRIcXFxmjJlipYsWVKl6wUAAAAAoKIIE+wYPXq0Jk+erGbNmlmdb9y4saZOnaquXbtq2rRpSk9P14IFC/SXv/zFbl/u7u6VGsOSJUuUkpIiBwcHLViwQP7+/payN954Q66urpo/f75iYmIUExOjwMDASr0OAAAAAABGsAGjHbNmzSoVJJQUEhKirl27SpJiYmKq/fULCgq0bt06SVK/fv2sggSzsWPHytPTU5K0Zs2aah8DAAAAAAC2ECZUQZcuXSRJly5dqva+Dxw4oIyMDEnSwIEDbdZxcXFRcHCwJGn37t26fv16tY8DAAAAAICbESZUweXLlyWpwpsf5uXlVbjvY8eOWY579Ohht565LDc3Vz///HOF+wcAAAAAoLLYM6GSLl++bNlYsWfPnmXWHT58uE6dOqX8/Hy5ubnJ19dXjzzyiEaOHCk3Nzebbc6cOSNJcnR0VKtWrez23aZNG6s299xzj9FLAQAAAADAEFYmVNK8efOUn58vSfrDH/5QZt3jx49b6mZnZ+vAgQMKCwvTkCFDFB8fb7PN1atXJUmNGjWSs7Oz3b69vb0tx2lpaYauAQAAAACAymBlQiVERkYqIiJCkhQUFKS+ffuWquPq6qrhw4crODhYnTp1UsuWLVVYWKj4+HitWbNGmzZtUlJSksaOHauIiIhSj5bMycmRJNWvX7/Msbi6ulqOs7Ozq3ppNmVmZurgwYM10rct99133y17LQDV61bOFbWJeQq4fd0J8xRzFHD7up3mKMIEg44ePar//d//lSTdddddeuedd2zWGzRokAYNGlTqvL+/v/z9/dW9e3eFhYXp8uXLmj9/vsLCwmp03AAAAAAAVBfCBAP+85//aMKECbp+/bo8PT21dOlSq9sMjHj++ee1adMmHT16VJs3b9bs2bOtbmdo0KCBpOKNFctS8gkO9vZfqCoPDw/5+PjUSN8Afl34NgxAXcc8BaAuu9VzVEJCgjIzMyvVlj0TKig5OVljxozR1atX5e7uriVLlqhz585V6jMoKEhS8e0JiYmJVmVeXl6SpIyMDBUUFNjtIzU11XLs6elZpfEAAAAAAFARhAkVcPnyZb3wwgu6ePGiXF1dtXDhQnXv3r3K/TZp0sRynJGRYVXWoUMHSVJRUZEuXLhgt4/z58+XagMAAAAAQE0iTChHenq6XnjhBZ09e1bOzs76+OOPdf/991dL3yaTyXLcqFEjqzI/Pz/L8ZEjR+z2ERcXJ6l4o8aqrpQAAAAAAKAiCBPKkJWVpXHjxunkyZNydHTUe++9p4cffrja+o+OjpYkubu7q127dlZl/v7+loBh8+bNNtvn5eVp27ZtkqQ+ffpYPdkBAAAAAICaQphgR15eniZNmqSjR49KkmbPnm3z6Qy2ZGZmlruJxeLFi3Xs2DFJ0sCBA602X5QkJycnjRw5UpK0fft2m48IWbFihWXPhNGjR1dobAAAAAAAVBVPc7ChsLBQr7/+uvbu3StJevXVVzVo0CBlZWXZbePm5iYHBwdJUlJSkp599lkNGjRIgYGB6tKlixo3bqy8vDzFx8dr7dq1llUJzZo106uvvmqzz/HjxysqKkopKSmaNGmSZs6cqYCAAF2/fl3r16/X4sWLJUmBgYEKDAyszh8BAAAAAAB2ESbYcPHiRcsv+5L08ccf6+OPPy6zTXR0tNq0aWP5c0ZGhsLDwxUeHm63TefOnfXRRx+pRYsWNss9PT21cOFCTZgwQSaTSTNmzChVp0ePHvrwww/LuyQAAAAAAKoNYUINuPvuuzVnzhzFxcXp+PHjunz5stLS0uTo6Chvb2/5+fkpODhYgwYNkouLS5l9+fr6KjIyUitWrFB0dLSSk5Pl7Oysjh07KiQkRKNGjZKTE3+NAAAAAIBbh99CbWjTpo0SEhIq3d7d3V0jRozQiBEjqmU83t7emjp1qqZOnVot/QEAAAAAUBVswAgAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmAAAAAAAAQwgTAAAAAACAIYQJAAAAAADAEMIEAAAAAABgCGECAAAAAAAwhDABAAAAAAAYQpgAAAAAAAAMIUwAAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAAAAAAAwhTAAAAAAAAIYQJgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADHGq7QGgYrZv367w8HAdO3ZM6enpatq0qXr37q3nnntOPj4+tT08AAAAAMAdhJUJt4FZs2Zp4sSJ2rFjh0wmk/Ly8pScnKwNGzbo97//vb755pvaHiIAAAAA4A5CmFDHLVmyROHh4ZKk4OBgRUREKDY2VsuWLVPXrl2Vl5enP/3pTzp48GAtjxQAAAAAcKcgTKjDUlNT9fnnn0uSAgIC9Omnn8rPz0/e3t4KCAjQypUr1bRpUxUUFOjdd9+t5dECAAAAAO4UhAl12Ndff63s7GxJ0pQpU+Tg4GBV7uXlpXHjxkmSjhw5omPHjt3yMQIAAAAA7jyECXXY9u3bJUl33323/Pz8bNYZOHCg5Xjbtm23ZFwAAAAAgDsbYUIdZl5pcO+999qt07JlS7Vo0cKqPgAAAAAANYkwoY5KSUmx3OLQtm3bMuu2adNGknTmzJkaHxcAAAAAAIQJddTVq1ctx02aNCmzrrk8LS2tRscEAAAAAIAkOdX2AGCbeVWCJNWvX7/MuubyrKysah1Dbm6uJCkzM/OWPnrSw8NDkvS97y17SQBVlJCQIKl4vrgTmOcpeW+u3YEAqLA7aZ6yzFGjmaOA20Vtz1Hm3/2MIEyAXYWFhbXyunfCmzyA2xvzFIC6jDkKgFGV+d2PMKGOcnNzsxyXlxKZy93d3at1DPXr11dubq7q1atX7uoIAAAAAMDtJTc3V4WFhZX6fY8woY7y8vKyHF+5cqXMuuZyT0/Pah2Dry/3GQAAAAAASmMDxjqqefPmltUJSUlJZdY9f/68JKlDhw41Pi4AAAAAAAgT6igHBwf5+flJko4ePWq33i+//KKUlBRJstQHAAAAAKAmESbUYf3795ckJSYm6sSJEzbrbN783116g4KCbsm4AAAAAAB3NsKEOmz48OGWWx3mzZunGzduWJWnpaVp6dKlkqR7772XlQkAAAAAgFuCMKEO8/b21uTJkyVJO3fu1KuvvqoTJ04oNTVVP/74o0JDQ2UymeTk5KTp06fX8mgBAAAAAHcKhxs3f92NOmfWrFkKDw+3Webs7Kw5c+Zo2LBht3hUAAAAAIA7FWHCbWL79u1au3atjh07pvT0dDVr1kwPPvignn/+efn4+NT28AAAAAAAdxDCBAAAAAAAYAh7JgAAAAAAAEMIEwAAAAAAgCGECQAAAAAAwBDCBAAAAAAAYAhhAgAAAAAAMIQwAQAAAAAAGEKYAAAAAAAADCFMAAAAAAAAhhAmALit7d27Vz4+PvLx8dH58+drezgAcEtERERY5j4Av36hoaHy8fHRjBkzqtSPed6IiIioppHhTkaYAKBOmjFjhnx8fBQaGlrbQwFwh6uuD/EAUBMIF1FbCBMAAAAAAIAhTrU9AACoigceeEAJCQm1PQwAAIAas2rVqmrph89MqE6sTAAAAAAAAIY43Lhx40ZtDwKAtRkzZujrr7/W/fffr1WrVik+Pl5Lly7Vvn37lJqaKi8vLz300EOaPHmy7r77brv9pKena/Xq1dq+fbvOnTunrKwseXt7y9/fX6GhoerZs2eZ44iPj9eiRYu0f/9+paenq1mzZgoMDNT48ePVunVry715YWFheuKJJ6za5ubmKjY2Vtu2bdPhw4d1/vx55efnq3HjxvL19dWQIUM0ePBgOTpaZ5oRERGaOXNmmeMaPny45s6dK6l4A8Znn31WkhQdHa02bdpIklavXq3Zs2fL0dFRO3bsUIsWLez2t3//fj3zzDOSpOXLl+uhhx4qVSc2Nlbr16/XoUOHdPnyZbm4uKh9+/b63e9+p2eeeUZubm5ljhm4U9X2fBYaGqp9+/ZZzRu22JrPPvnkE3366adlXt/LL7+sV155xap+69attW3bNv38889asWKFYmNjdenSJbm6uurAgQOSpBs3bujo0aPatm2bYmNjdfbsWWVlZcnd3V0dO3ZUUFCQRo8eLQ8PD5uvW3Ku5JtGoOJunpP279+vFStW6MiRI8rIyFDLli0VHBysF198UZ6ennb7SUhI0MqVK7V3715dunRJTk5Oatu2rfr166fnnntO3t7edtseOnRIa9as0eHDh2UymeTg4CBvb281b95cvXr10qOPPqru3btbtbE1l50/f14DBgwo83rN85GZrbnu559/1uDBgyVJ8+bN0+OPP263v5ycHPXp00fZ2dmaOHGi3njjjVJ1zpw5o3/84x+KjY3VxYsXVVRUpJYtW6pv374aM2aMWrVqVeaYcfvgNgegjvvuu+80ffp05eXlWc5dunRJX3/9tbZt26ZVq1bZ3HBnz549eu2115SWlmZ1PiUlRZs2bdKmTZs0efJkvfbaazZfNzIyUjNnzlRBQYHl3IULF7R27Vp9//33WrZsWZnjnjdvnr788stS5y9fvqyYmBjFxMQoKipKn376qVxcXMrsqzIGDRqksLAw5efnKyoqSuPGjbNbNyoqSpLUrFkz9e7d26osNzdXf/zjH7Vx40ar83l5efrpp5/0008/ad26dVq6dKnat29f7dcB/JrU1nxWG7Zu3aopU6YoNzfXcs7V1dVyHB0drZdeeqlUu/T0dB0+fFiHDx/W+vXrtWzZMrVt2/aWjBm404SHh+uvf/2rioqKLOfOnTun5cuXa+PGjfryyy/VsWPHUu2WLVumDz74wKpdbm6u4uPjFR8fr7Vr1+qzzz5Tr169bLZ97733Sp1PTk5WcnKy4uLidOrUKS1atKiarrJ8nTt3lp+fn44dO6bIyMgyw4To6GhlZ2dLkoYMGVKqfPny5Zo3b57V50dJOnv2rM6ePav169fr73//u/r371+9F4FaQZgA1GGJiYmaPn267r33Xk2aNEndunVTXl6etmzZog8++EDp6emaNWuWwsPDrdodO3ZM48ePV15ennx9fTV+/Hj16NFD7u7uSkpK0urVqxUREaHPP/9crVq10ogRI6zax8fHW4KEFi1aaOrUqZZfsmNjY/XBBx/o9ddfL3PsDRs21MiRI9WnTx+1bdtWzZo1k6Ojoy5evKjvv/9ea9as0Q8//KD58+frrbfesrQbMmSIfve732nWrFmKiorSfffdpyVLllj17ezsXO7PzsvLS3379tW2bdsUGRlpN0zIy8vT5s2bJUmPP/54qZUSb775prZs2SJnZ2eFhoZq8ODBatOmja5fv649e/Zo/vz5SkpK0sSJExUREcEKBcCO2prPquLFF1/UmDFjNH78eB08eFAhISH661//alXH1nyUnp6ut956S3fffbdeffVV9ezZU0VFRfr3v/9tqePk5KSgoCAFBQWpU6dOat68udzd3XXp0iXFxsZqxYoVSkxM1JQpU/TVV19V2zUBKJaYmKg5c+bIz89Pb7zxhrp166Zr165p48aNWrBggS5duqRJkyYpMjJS9evXt7SLioqyhAFdu3bVG2+8oXvvvVe5ubnavn27PvroI6Wnp2vChAmKjIy0CgPPnDmjefPmSZJ69+6tsWPHqlOnTvLw8FBGRoZOnz6tnTt36tq1axW6htatW+vQoUOKiorSrFmzJBWveijp5s819gwZMkTHjh3Tjz/+qNTUVLsrKyIjIyVJfn5+6tSpk1XZ6tWr9e6770qSHn30UY0ePVpdunSRo6Ojjh8/rk8//VSHDx/Wa6+9pvXr16tr164VGhvqLsIEoA5LSUlR3759tXDhQjk5/fd/1+eee05FRUWaO3euDh8+rNOnT1tN6DNnzlReXp569OihVatWWX3z37hxY4WFhalZs2ZatGiRPvzwQ4WEhFh9Y/b++++roKBAHh4eWr16tdUb4dChQ9WjRw8NGzaszLGbl/3erFmzZurevbt69+6t8ePHa+3atZo8ebJlKa+Tk5PlH0mqV6+e3N3dDfzU/mvo0KHatm2bEhISdPLkSZtvWjExMUpPT7fUL+lf//qXtmzZIgcHB3300UellhIOGzZMDz74oIYPH64zZ85o7dq1Gjt2bKXGCvza1dZ8VhUuLi5ycXFRvXr1JBXPTxWZjzIzM9W+fXutXbtWDRs2tJwvebtVv3791K9fv1Jtvby85OPjo0GDBunxxx/X0aNHFRsbW2rVFICqSUlJ0f/8z/9o1apVatCggSTJ29u01udFAAAgAElEQVRbL730ktq2bas333xTZ8+e1erVqzVmzBhJxV9AhIWFSZI6duyotWvXWt2K9PTTT6tnz5566qmnlJ2drXfffdfqVqldu3apsLBQTZo00eLFi63ms0aNGqlNmzZ6+OGHK3wNDg4Ocnd3t+qnsp+ZBg8erPfee08FBQXatGmTzUdzp6am6scff5RUelXCpUuXLLdfvPDCC6UepRsQEKAHHnhAL7zwgvbv36958+bd0tUXqBlswAjUcX/605+sPnibDR8+3HJc8tuuPXv2WO6f/dvf/mb3FoLJkyfLzc1Nqamp2rVrl+X8pUuXLG8UoaGhNpfXtmvXzuabjBGBgYHy9vZWdna2Dh8+XKW+7AkKCrJ8kDcn6Tczn+/SpYu6detmVbZy5UpJ0sCBA+3ek9iyZUs9/fTTkv57uwQA2271fFabXnvtNasgwajmzZtbAoTdu3dX17AAlDB16lRLkFDSkCFDLHsWREREWM5v27ZNV65ckSRNmzbN5p4mvr6+euqppyz1U1NTLWWFhYWSikOLmrjFsypK3upp7/PMd999p4KCAtWrV6/UrRDh4eHKy8tTy5YtNW3aNJvtnZ2dLbej/fDDD8rIyKjGK0BtIEwA6rC2bduqQ4cONss8PT0tS9AuX75sOR8bGytJatWqlVq2bKmsrCyb/xQWFlr6/umnnyztjxw5IvO+rEFBQXbHVt6GP1Jxgr1gwQKNHj1aDz74oPz8/OTj42P5x/wGe/bs2XL7qgwXFxc99thjkqSNGzfq5v1mr127pu3bt0sqnbDn5OQoLi5OUvHjJ+39HLOysiwrHhISEqzuBQfwX7Uxn9UWBwcHBQYGllsvPz9fX331lSZMmKDAwEB1797dao4034JVU3MkcCdzc3OzueGy2SOPPCKpeHNC8y+9Bw8elCQ1aNCgzBUE5s8ehYWFVrcdmL+0OHXqlD744ANdvXq1ahdRzcwrNI8cOaLExMRS5eaQoXfv3mratKlVmTn07NWrl3Jzc+3O1+aVZzdu3NCxY8dq8nJwC3CbA1CHNW/evMxyc5p+/fp1y7kzZ85IKt7I57e//W2FXqdkan7hwgXLsa1NhypSJkkHDhzQSy+9VGrDNFsqem9gZQwZMkRfffWVLl68qH379umBBx6wlG3evFl5eXlycHBQSEiIVbukpCTl5+dLkmbNmmW5F7EsRUVFlqdeALBWG/NZbfHy8rL7FAYzk8mkMWPG6OTJk+X2V5NzJHCnateuneUWJlvMn3Nu3Lih5ORkNWrUSMnJyZKk9u3b21xlZdalSxfLsbmNVPzlRHBwsLZu3aolS5Zo+fLluueee3TffffJ399fvXv3rtW9l4KDg+Xm5qbs7GxFRkZa3bJ67tw5y5cstjZeNM/XUVFRFV6pWRfma1QNKxOAOqysN7mSSn7jXpkPnSW/TTfv0CvJ5tI/s7Le7K5du6aXX35ZaWlpatKkiaZNm6Z169Zp586dOnjwoA4dOqRDhw7prrvukvTfZX81oVevXmrdurWk0rc6mN/sevXqZRlLyWuojJI7twP4r9qYz2pLWXOn2VtvvaWTJ0/K2dlZzz//vL744gtt27ZN+/bts8yR5mXENTlHAneq8n5pL1melZVl9e/y2pbct8Dcxsy88XTbtm1VWFioI0eOaPny5Zo8ebL69Omjt99+W5mZmYaupbq4ublZVmTcHAiYP0OVrFNSZcbMZ6bbHysTgF8Z8xtc9+7dK7UDeMk3yJycHLvfrpUMHW62efNmXb16VY6Ojlq5cqU6d+5ss96teLN0cHDQ448/rkWLFmnLli2aNWuWXFxc9Msvv2j//v2SbCfsJT8ILF682NCGSACqR1Xns4q6+RFmNe3cuXOWJcF//vOfNWrUKJv1cnJybuWwgDtKWZ9jbi43fyYw/7sybc2cnZ01duxYjR07VomJiTp8+LAOHDigHTt2yGQy6R//+Ifi4uL0z3/+s8zVDzVlyJAh+vbbb5WYmKi4uDj16NFD0n/DBfPqhZu5ubkpIyND48aN05tvvnlLx4zaw8oE4FfGvGFiUlJSqT0CKqJVq1aWY/OSNVvKKjNvmObj42M3SLh48eItW7prvgew5B4JGzduVFFRkerXr2+5t7Gk1q1bWx6nlJSUdEvGCcBaVeczSZZHupW8feJmly5dqlTflRUfH285Hjx4sN16FbkFAkDlJCYmlrnq5z//+Y+k4i8lzJ+NzCsdz549W2YIeerUKcuxuY0t7dq107BhwzRnzhzt2LHDsrn1Tz/9pB07dlT4WqpT7969LbdrmgOEo0ePWvZusfUFjGQ9X+POQZgA/MqYNxO6evWq9uzZY7h9jx495ODgIKl4F2J7oqOj7ZaZlxmX9SZd3v105jS+Opb3durUSX5+fpL+u0zP/O9+/frZ3HG9YcOGlp2cv/vuuyqPAYBxVZ3PJFk+FJcVgO7cubPMPqpzPpKsb8Ww12dcXBwfyoEalJ2dbXl6lS1bt26VJHXu3FmNGjWSJN13332SilcNlTVvbNmyRVLx7V09e/as0HicnJys9ig4ffp0hdqZ25pVdZ4q+aQG89MbzJ+ZmjVrpj59+thsZ56vd+3axVMa7iCECcCvTEBAgOXpAn/5y1+sdka35fz581YfbJs3b255o1i1apXOnz9fqk1SUpJWrVplt882bdpIKv7wbms34NOnT2vhwoVljsvT01NS9X1jaE7Sf/jhB+3fv9+yesK8asGWF154QVLx7s0rVqwos//CwkKb1wqg8qo6n0nSvffeK6l4NUDJFQFmly9f1meffVZmv9U9H5nnSEmW1VIlZWVl6a9//Wu1vBYA++bNm2fzdqKoqCgdOXJEkvTEE09Yzvfv319NmjSRJH3wwQc2b9eMj4/X2rVrJRU/+cr8pBqpeEVDUVGR3fGcO3fOcmyedyqiZN3qmKfMn41SU1P1ww8/6Pvvv5dUvJLK3v43Tz/9tFxcXJSVlaU///nPlk2s7TGv/MDtjTAB+JVxcHDQ3Llz5erqqrNnz2ro0KFatmyZTp48qfT0dF25ckUnTpzQV199pYkTJ+rRRx8t9WY4bdo01atXT9euXdMzzzyjqKgomUwmmUwmRUZG6plnnrF6c7zZo48+KkdHR+Xn52vChAmKjo6WyWRScnKy1qxZo6effloNGjQo843SvJIgKSlJq1ev1pUrV1RQUKCCgoIy34jtefzxx1WvXj3l5+dr+vTpkorffMt6fNtjjz1mWYI8d+5cvfTSS/rhhx+UkpKijIwMXbhwQTExMXr//fcVHBysL7/80vC4ANhXHfPZY489ZrlnefLkyYqOjtbVq1eVkpKib7/9ViNHjrTcCmGPeT46ePCgvv/+e6WlpVVpPvrNb35jCRTmzJmj1atXKykpSVeuXFF0dLRGjRql+Ph4u4/SBFB1zZs31+nTpxUaGqrdu3fr6tWrOnfunD777DPNnDlTUvFTG55++mlLGxcXF0vZzz//rNGjR2v79u1KTU3VxYsXtXbtWj333HPKy8uTm5tbqb0DFi5cqODgYM2bN08//vijLl68qIyMDJ07d04bNmywrExwc3NT//79K3wtvr6+llszP/74Y124cEF5eXkqKCio1EqFbt26WZ5I8c4771iCXHu3OEhSy5Yt9cc//lFS8cqMESNG6JtvvlFSUpKuXbumlJQUHThwQEuXLtWTTz6pV1991fC4UPewASPwK+Tn56cVK1bo9ddfV0pKit577z299957NuvWq1evVMrs6+urv/3tb/rjH/+oixcvatq0aVbljRs31ieffKIRI0ZY+iipffv2ev311/Xhhx/q7Nmzmjx5slV5w4YN9cknn2j69Ol2Hx3Zv39/tW3bVklJSZo9e7Zmz55tKRs+fLjmzp1bsR/G/69p06bq06ePdu7caXn85cCBA+Xs7Fxmu7lz58rDw0P//Oc/tXXrVsuyR1vK6wuAcVWdzzw9PfWXv/xF06dP14ULF0rNRy1atNDixYvL3Ltg6NChWrx4sdLT0/X6669blb388stWS5Mrol69enrnnXc0YcIEZWZmWs1vkuTo6Kjp06crPj6+zNszAFRe+/btNWnSJL399tuWlYglNW/eXAsWLCgVNoaEhOjSpUv64IMPlJCQoIkTJ5Zq27hxY3322We6++67S5VduHBBixcv1uLFi22Oy9XVVe+//365j9MtqWnTpho0aJA2btyoiIgIRUREWMpat25d5m2r9gwZMkTz5s2zfGYqecuoPX/4wx/k6OioOXPm6MSJE5Yvb2zx9fU1PCbUPYQJwK/Ub3/7W23ZskUbNmzQtm3blJCQoPT0dNWrV09NmzZVly5d1Lt3bz322GNq3LhxqfbDhg1T165dtWjRIu3fv18ZGRlq1qyZAgICNGHCBHl5eVnq3rxTsSS9+OKL6tSpk7788ksdO3ZMBQUFatGihR566CGNHTvWslGPPa6urlq9erU+//xzxcbG6pdffqnyI4SGDh1qdY9jWQm7mYuLi2bPnq2nnnpK//znP3XgwAHLWDw8PNS2bVv16NFD/fr1s3sfIYCqqep8NmTIEN11111avHixjh49quzsbLVs2VLBwcEaP358mSutpOL7hMPDw7Vw4ULt379fJpOp3CW85XnwwQe1bt06ff7559q3b58yMzPl5eWlnj17KjQ0VL169dKMGTOq9BoAyjZ69Gh17NhRX3zxhY4ePapr166pZcuWGjBggCZOnGh3BeXYsWP10EMPaeXKldq7d69MJpPq1auntm3bqn///nruuedszivTpk1T7969tWfPHp04cUImk0lpaWmqX7++2rVrp969e+uZZ56x2gy7osLCwtS5c2dt2bJFiYmJysnJqfTGtVLxvPn3v//dsvqqIp+ZJOmpp55Sv379tGbNGu3evVvnzp3TtWvX5Orqqrvuuku+vr7q27evgoODKz021B0ON6ryXxmAO9bx48c1fPhwSdKGDRt0zz331PKIAAAAyjZjxgx9/fXXuv/++8vc/wlA+dgzAUClmJfMubi4WDZIAwAAAHBnIEwAYJO9vQyk4t2IzU83CAoKkouLy60aFgAAAIA6gD0TANj01ltvyd3dXYMHD5afn5/c3d1lMpm0c+dOLVy4UJmZmXJ2di61mRkAAACAXz/CBAA2FRYW6rvvvtN3331ns9zFxUXvvvuufHx8bvHIAAAAANQ2wgQANr3yyivq2rWr9u/fr5SUFF29elUuLi5q1aqVevfurWeffbbcJzIAAAAA+HXiaQ4AAAAAAMAQNmAEAAAAAACGECYAAAAAAABDCBMAAAAAAIAhhAkAAAAAAMAQwgQAAAAAAGAIYQIAAAAAADCEMAEAAAAAABhCmAAAwK/Y3r175ePjIx8fH0VERNT2cFADIiIiLH/He/fure3hAADuEIQJAAAAAADAEMIEAACAOiYoKEg+Pj4KDQ2t7aHc9li5AQA1w6m2BwAAAGrOAw88oISEhNoeBmrQE088oSeeeKK2hwEAuMOwMgEAAAAAABhCmAAAAAAAAAxxuHHjxo3aHgQAAHVdRESEZs6cKUlauXKl7r//fm3cuFHffPONEhISlJqaqi5duujbb7+1apeVlaV169Zpx44dOn36tNLS0uTu7q4OHTqoX79+Gj16tBo1amTVJi8vTwEBAUpPT1fPnj0VHh5e7vhGjx6tgwcPqmHDhvrxxx9Vv359ScVPc3j22WclSWFhYWUuh09NTdXatWu1c+dOJSYm6tq1a2rYsKG6dOmiRx55RCNGjJCrq2updk8++aR++ukn+fn52XxiRHZ2tu6//37l5+dLkhYvXqyHH364VL33339fS5culaOjo/bs2aPGjRuXe903i4mJ0ddff61///vfMplMKiwslKenp7y8vOTr66uHHnpIwcHBcnNzs9m+qKhImzdv1ubNm/Xvf/9bV65ckZOTk1q1aqUHH3xQoaGhateunc2258+f14ABAyRJL7/8sl555RWdOHFCX3zxhfbt2yeTyaSGDRvq3nvv1ZgxY3T//feX6iM0NFT79u0r9zqjo6PVpk0bSaX/23zggQes6toqj4yM1Pr163Xq1Cnl5OSoTZs2GjJkiEJDQ9WgQQNL29jYWK1atUrHjh1TamqqmjVrpgEDBmjy5Mny8vIqd5wXLlzQ2rVrtXv3bl24cEFZWVny9PRUt27dNGjQIIWEhMjJyfZdtzNmzNDXX38tSUpISFB+fr7Wrl2ryMhIJSYmKj8/X23atNGjjz6qMWPGyMPDw6p9yf/2yzJ8+HDNnTu33HoAAGvsmQAAgEF5eXmaOHGiduzYUWa92NhYTZ06VVeuXLE6n5aWpsOHD+vw4cP68ssv9fHHH6tXr16WchcXFw0cOFDh4eE6fPiwEhMT7f4CK0lJSUk6dOiQJGngwIGWIMGIqKgozZo1S1lZWVbnU1NTtXfvXu3du1crV67U559/ri5duljVefDBB/XTTz/pxIkTSk9PLxUCHDhwwBIkSNKePXtshgl79uyRJHXr1s1wkFBUVKTp06crMjKyVJnJZJLJZNLJkyf1zTffaPX/1969B1VV9X0A/4KCCqgnIJExFWLcqIAEiRxRS7loadw0E0FzwsuUlxwrRzMnS3oML5WOaTmhU9IjkSFYqAMKIgoSmqiJokQoCCrKOeBBkOt+/+A9++FwLnAQ3nrevp8ZR85ea6+19mbP6P6dtX7r3//G2LFjteqVlZVhxYoVyM/P1zheX1+PwsJCFBYWIi4uDu+//z7mzZvX4Zji4+MRFRWlce0KhQInT55ERkYGNmzYgLlz5xp1nU+qubkZb7/9NlJSUjSOFxYW4rPPPkNmZia++eYb9O3bF1u2bMG+ffs06pWVlWH//v3IyMhAXFwcbG1t9fa1d+9efPHFFxrXD/zn95GZmYnY2Fh89dVXsLOzMzhuhUKBxYsX48qVK1rjLiwsRGpqKmJjYzsV4CAiou7BYAIREZGRtm3bhoKCAkycOBGzZs3CsGHDoFKp8Oeff0p1srKysGTJEjQ1NUEmk2Hu3LlwdXXF4MGDUVNTg7Nnz+L777+HQqHAkiVL8OOPP2q8pIeEhEgzEpKSkrBy5Uq94zl8+DDUEw2Dg4ONvp6EhASsW7cOAGBnZ4eIiAgIgoBBgwZBqVTi1KlTiIuLQ0lJCd544w0kJibi6aefls6Xy+WIiYlBS0sLcnNzERAQoNG+OkigpiujvkqlwrVr1wBA65v1zvjhhx+kQIKTkxPCwsIwYsQIyGQy1NbW4tatW/jtt9+Qnp6u8/x79+5hzpw5uH//PszMzBAUFIQJEyZgyJAhEEURV65cwf79+1FSUoKoqChYWloiNDRU73iysrJw6dIlODk5YcGCBXB2dkZTUxMyMzMRExODxsZG/Otf/4JcLoejo6N03qZNm1BXV4eFCxeioqICrq6u+PTTT7Xa7+jlW58dO3bg4sWLeOmllxAcHAw7OzuUl5djz549+P3333Hu3DnExMTAysoK+/btw/jx4zFnzhwMGzYMlZWV+O6773DmzBmUlJQgOjoa27Zt09nPzp078eWXXwIAHB0dMXfuXDg6OsLGxgYVFRVITU1FUlIS8vPzsWjRIsTHx+udLQIAy5Ytw/Xr1xEeHg4/Pz9YW1ujtLQUMTExuHz5MgoLC7F582aNGQZubm745ZdfkJaWhu3bt0v3183NTaPtrsyAISIiACIRERF1KCEhQRQEQfqzZcsWvXVVKpUol8tFQRDEBQsWiCqVSme94uJijXrtTZ06VRQEQfT19RVbWlr09hcQECAKgiD6+flpleXk5EhjTkhI0CovKSkR3dzcREEQxNWrV4v19fU6+7hw4YI4ZswYURAEcd26dRpltbW1oouLiygIgrhx40atc0NDQ0VBEMSlS5eKgiCII0eOFKuqqjTqnDhxQhpnRkaG3mvVJzw8XBQEQZw8ebLe+y2KolhfXy/W1NRoHY+MjBQFQRBffPFFsaioSOe5jx49EsPCwkRBEEQvLy+tfkpLSzWekcjISJ33MzExUaqzadMmnX1NmTJFFARBnDdvnqHLFkVR89nMyckxWC4Igrhnzx6tOjU1NeLkyZNFQRBET09P0dXVVdywYYNWvcbGRnHWrFmiIAiii4uLWFlZqVXn/PnzorOzsygIgrht2zaxublZ57hTU1Olert27dIqX7NmjTTm0aNHi1lZWVp16urqxOnTpxscT0f3h4iIuoYJGImIiIw0fPhwrFq1Sm95XFwcFAoF+vXrh88//1xrLbeag4MDli1bBqB1SURpaalGuXqWwe3bt3H+/HmdbaiXQQCtsxmMtXfvXtTX18Pe3h5RUVEwNzfXWc/DwwPh4eEAgJ9//hmPHz+Wyvr164cxY8YA0J6F8PDhQ2nGQWRkJAYMGICWlhat2Qnq88zMzHQuQejIgwcPAAAuLi567zfQuoTE0tJS49jly5dx5swZAMBHH32EZ599Vue5FhYW+PjjjwEA1dXVWksF2urTpw82b96s834GBQVJMzvOnTtn4Kq6n6urK5YsWaJ13NLSUnp+ampqIJPJpNkqbfXu3RthYWEAgMbGRuTl5WnV+frrryGKIsaMGYN33nkHpqa6/7sZEBCAqVOnAgAOHjxocNwRERHw8fHROt63b19ERERI47l48aLBdoiIqPswmEBERGSk6dOn600aBwDHjx8HAIwfPx7W1tYG22qbhE+d90AtODgYJiYmAFqXOuiiPm5iYtKlJQ4nTpwAAPj7+3eYa0E91oaGBq2163K5HADwxx9/SC/2AJCbm4uWlhZYWlrC3d1dyg3RPuig/uzq6qr1st8Z6mn/586dw82bN406NzU1FQDQv39/nbkc2hIEATKZDID276stHx8fvfkETE1N4eLiAgBaAaSe9sorr+gtGzVqlPTztGnT9AaW2ta7ffu2RtmjR4+QnZ0NAJgxY4b0/OqjfqbKy8tx9+5dvfWCgoL0lrVdtvB/fT+JiP7JmDOBiIjISCNHjtRb1tzcLCXwS09Ph7Ozc6fbvX//vsbnIUOGwMvLC7m5uUhJScGHH36o8cLf0NCAY8eOAQA8PT0xdOhQYy4D5eXlUp+xsbGIjY3t8ljlcjl27doFoDUwoH5pVQcJvLy80Lt3b3h7eyMtLU0jmKBQKFBYWCi10xWzZ8/Gr7/+iqqqKgQGBmLKlCmYNGkS3N3d4eTkhF69euk99/LlywBa8zYY+t221/4etNU2D4Iu6nX6NTU1ne6vO+ibdQG0BlPUDI2/7e4j7cd/9epVNDU1AWjdPURXvgd9KioqMHjwYJ1lhsatDu7oGg8REfUczkwgIiIykqGEbdXV1dLLlLHaLh1QU089V6lU0iwCtYyMDFRXV2vUM0b7XSaM0X6szz33nLRtZNtAgfpndZBA/XdRUREqKioAtCZkFP83gWRXgwmBgYFYvXo1+vbti4aGBqSkpGD9+vUIDAyEt7c3VqxYgfT0dKmfthQKRZf6rKur01tmKJkgAGnqf0tLS5f67ipdW3uqtV2O0HZ7yPbazjZoP/7ufKbaMnQ/DY2HiIh6DmcmEBERGUnfGnCgdWaCmr+/v8FdGNqzsbHROjZt2jRERUWhrq4Ohw8fxowZM6Qy9RKHPn364OWXX+50P7rGGh4ebtQ2he2/QTY3N4enpyeys7OlAEJlZaXWjANBEGBjY4PKykrk5OQgKChIqt+nTx94enoafR1qixYtQmhoKI4ePYrs7Gzk5eVBqVRCpVIhNTUVqampGDduHHbv3q3xLbw6+GNnZ4eYmJhO92fohfufqu0ztWrVKvj6+nb63GeeeaYnhkRERD2EwQQiIqJuJJPJYGJiAlEU0djYCEEQnqg9Kysr+Pn5ITk5GVlZWXjw4AFsbW2hVCqRmZkJAPDz89N4Oe6s9vkcnnSscrkc2dnZKC0tRVlZmZQMTyaTScsHTExMMG7cOBw7dkwKJqiTMXp4eOhdp99ZNjY2mD9/PubPnw+gdQbEqVOncODAAZSWliI3NxcbN27E1q1bpXOsra1RXFwMlUqFESNGdLjOn/Rr+0z17t37iZ8pIiL6++IyByIiom5kZmYm5Um4dOkSGhsbn7hN9RKGpqYmJCcnAwCOHj0qtd2VJQ5A6zfB6vXm+naLMEbbJQo5OTnSjANvb2+NF3R1vZycHNy7dw/FxcVa53cXJycnREZGIiEhQUrSmJKSorEURZ0Msba2Vsp3QV0zatQoaeZOdzxT3YHBISKinsFgAhERUTcLCAgAAFRVVeGnn3564vZ8fHwwaNAgAP9Z2nD48GEAgK2tLSZOnNildk1NTaVp6Ddu3JBmOnSVq6urtC1j22BC+yCB+nNZWZnGloA9EUxQGzhwoLR9ZX19PWpra6Uy9faEQOtWmX8H6twGDQ0Nf/FIjCOTyaQdOzIzM6VlLn+l9klLiYioezCYQERE1M1ef/116Rv/6OhonD592mB9hUJhcCeFXr16ITAwEABw7do1pKSk4NKlSwBaEw8a2qmgI2+++aa0tGDt2rVaWz62d+fOHY0AQPtxql8kT548iZKSEgDaQQIHBwfY29sDAL799lsAgKWlpcYWf8ZKTEw0+KJYXV0t3TOZTKaxI4GXl5c0xqNHj2L37t0G+2poaMDBgwc1tsDsburg0a1bt3Qmjfw7W7FiBUxMTNDc3Izly5d3uF1jUVERjhw50mPjUd9LAEZvG0pERPoxZwIREVE3GzBgAHbs2IFFixbh8ePHWLx4Mfz9/REQEAAHBweYmZmhuroaN27cQE5ODk6fPg1ra2tpnb8uISEh0rfm69ev1zj+JIYPH45PPvkEa9asQWVlJcLCwjBjxgxMnjwZQ4YMgampKZRKJa5fv44zZ84gNzcX7u7umD17ts725HI5Tp48CZVKBaA1qaGubf28vb2RlJQk1Rs7dix69+76f0vWrl2L6Oho+Pr6wtPTE46OjrC0tER1dTUKCt/a/lcAAAO7SURBVAoQFxcn7R4RERGhdf7WrVvx2muv4c6dO9ixYwdOnDiBmTNnYuTIkbC0tMSjR49QXFyMvLw8pKWloaqqCqmpqbC1te3ymA0ZO3Yszp49C6VSiQ0bNiAkJERjF5Fhw4bBzMysR/p+Ul5eXli5ciW2b9+OmzdvIjAwEKGhoZgwYQIGDx6MlpYWVFZW4tq1azh16hQuXryIwMBAjeSi3Wn06NGwsLBAbW0tYmJiYGNjAycnJ+l569+/v0bAgYiIOofBBCIioh4gl8sRGxuLd999F2VlZTh+/DiOHz+ut35HCRQFQcDo0aNx9epVPHz4EADg7OwsJTZ8EsHBwbCyssIHH3wApVKJpKQkaTmFsWNtPwvB29tbb722fXTHEoeqqiocOnQIhw4d0lvn1VdfxdKlS7WODxo0CPHx8XjvvfeQm5uL/Px8g/kTzM3NnzhZpCFhYWGIi4vDgwcPEB8fj/j4eI3ytLS0v/XuB2+99Rasra0RHR2N2tpaHDhwAAcOHNBbvysJRDvLwsICCxcuxM6dO3H37l2sWrVKozw0NBTR0dE91j8R0f9XDCYQERH1EA8PD6SkpCA5ORnp6enIz8+HQqFAU1MTrKysMHToULi5uWHixImYNGlSh+2FhITg6tWrGp+7i5+fH8aPH49Dhw4hMzMTBQUFUCqVEEURAwcOxPDhw+Hu7o4XXnhBb4AAaA1wPPXUU1AqlQD0Bwn05VHoqiNHjuD06dO4cOECbt68CYVCgaqqKpibm8Pe3h4eHh6YOXMmnn/+eb1t2NnZITY2FtnZ2UhOTkZeXh4qKipQV1cHCwsL2Nvbw9nZGT4+PvD399dYKtHdbG1tkZCQgJiYGJw9exbl5eWoq6v7r1ryMGfOHEydOhUHDx5EVlYWioqKUFVVBVNTU8hkMjg4OMDDwwO+vr5wd3fv0bEsX74cDg4OSExMREFBAaqrq7slOSoR0T+Zifjf9K8SEREREREREf3lmICRiIiIiIiIiIzCYAIRERERERERGYXBBCIiIiIiIiIyCoMJRERERERERGQUBhOIiIiIiIiIyCgMJhARERERERGRURhMICIiIiIiIiKjMJhAREREREREREZhMIGIiIiIiIiIjMJgAhEREREREREZhcEEIiIiIiIiIjIKgwlEREREREREZBQGE4iIiIiIiIjIKAwmEBEREREREZFRGEwgIiIiIiIiIqMwmEBERERERERERmEwgYiIiIiIiIiMwmACERERERERERmFwQQiIiIiIiIiMsr/AOHmRucFPiyRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "image/png": {
              "width": 521,
              "height": 381
            }
          }
        }
      ],
      "source": [
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "S7_ACkTsHxF8"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 1\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_MfBUiNjDuq",
        "outputId": "120d9e1d-7ee3-456a-dd0e-68fd9a245500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PvjMjcOAMNi0"
      },
      "outputs": [],
      "source": [
        "# Делим данные на обучающую, тестовую и валидационную выборки\n",
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
        "train_texts = list(df_train[\"content\"])\n",
        "train_labels = list(df_train[\"sentiment\"])\n",
        "test_texts = list(df_test[\"content\"])\n",
        "test_labels = list(df_test[\"sentiment\"])\n",
        "val_texts = list(df_val[\"content\"])\n",
        "val_labels = list(df_val[\"sentiment\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "max_len = 160  # максимальная длина последовательности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "l5tXYtsDXJWu"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_len)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_len)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "outputs": [],
      "source": [
        "# Dataset, который на каждой итерации будет возвращать токенизированный отзыв и класс\n",
        "\n",
        "class GPReviewDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = GPReviewDataset(train_encodings, train_labels)\n",
        "val_dataset = GPReviewDataset(val_encodings, val_labels)\n",
        "test_dataset = GPReviewDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YRs3y_xTBjuW"
      },
      "outputs": [],
      "source": [
        "# метрики\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2I0i_TycDOxA"
      },
      "outputs": [],
      "source": [
        "# параметры обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H63Y-TjyRC7S"
      },
      "source": [
        "## Классификация сентимента"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.n_classes = n_classes\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size*4, n_classes)\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        last_hidden_state, hidden_states = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=False)\n",
        "        cls_tokens = []\n",
        "        for hidden_state in hidden_states[-4:]:\n",
        "            cls_tokens.append(hidden_state[:, 0, : ])\n",
        "        pooled_output = torch.cat(cls_tokens, 1)  # пришлось написать\n",
        "        output = self.drop(pooled_output)\n",
        "        logits = self.out(output)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.n_classes), labels.view(-1))\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0yQnuSFsjDp",
        "outputId": "2450731f-33ee-435f-a538-5a579d3f24c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)\n",
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZj8dbS2lh52",
        "outputId": "89eecd5a-fc33-438e-cfca-1c1125790dd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "50WE2-a6F_17",
        "outputId": "f2a5a9eb-2cd7-4eda-a616-e33c5717e3d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 5400\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1350\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 06:12, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.160100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.183800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.201500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.121500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.130200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.091700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.094200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.100700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.060600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.963200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.983800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.901700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.885900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.809800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.800500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.915300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.857500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.837100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.923200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.723200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.746000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.763100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.794400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.797600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.739900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.751600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.851400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.711000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.911300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.855600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.842400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.824600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.795000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.818400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.853600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.748100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.776300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.731300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.827300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.746300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.797600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.722800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.813800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.964900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.866900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.658000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.659700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.961000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.703600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.936200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.900700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.804900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.771200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.787500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.752400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.849800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.567100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.561600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.725600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.541900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.498100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.688500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.615300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.506300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.540800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.651800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.673400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.561700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.641000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.652300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.472300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.470600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.498300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.683400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.609000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.517800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.713400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.582700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.655300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.638200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.607600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.450600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.478000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.514500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.533700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.431500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.388300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.557000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.514000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.409800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.463700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.424400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.523200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.362200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.560900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.558100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.460200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.424000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.397800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.484200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.393000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.411800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.297200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.449300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.512000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.687700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.480600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.531300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.564400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.575900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.610900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.487900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1350, training_loss=0.7102192163467407, metrics={'train_runtime': 372.6203, 'train_samples_per_second': 28.984, 'train_steps_per_second': 3.623, 'total_flos': 0.0, 'train_loss': 0.7102192163467407, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "aqq9p9LsGFXk",
        "outputId": "f6e3ca76-a1e1-4804-b72d-3ede325c6746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.8        0.71559633 0.81218274]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.90243902 0.67826087 0.77669903]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.7184466  0.75728155 0.85106383]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.7733333333333333,\n",
              " 'eval_f1': array([0.8       , 0.71559633, 0.81218274]),\n",
              " 'eval_loss': 0.6019710302352905,\n",
              " 'eval_precision': array([0.90243902, 0.67826087, 0.77669903]),\n",
              " 'eval_recall': array([0.7184466 , 0.75728155, 0.85106383]),\n",
              " 'eval_runtime': 2.9721,\n",
              " 'eval_samples_per_second': 100.938,\n",
              " 'eval_steps_per_second': 6.393}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "YcoMiEGbGK0p",
        "outputId": "33f55644-fab2-4208-aa28-5f695b2a4bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.85087719 0.75       0.87777778]\" of type <class 'numpy.ndarray'> for key \"test/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.88181818 0.70588235 0.89772727]\" of type <class 'numpy.ndarray'> for key \"test/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.8220339  0.8        0.85869565]\" of type <class 'numpy.ndarray'> for key \"test/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'test_accuracy': 0.8266666666666667,\n",
              " 'test_f1': array([0.85087719, 0.75      , 0.87777778]),\n",
              " 'test_loss': 0.4994933009147644,\n",
              " 'test_precision': array([0.88181818, 0.70588235, 0.89772727]),\n",
              " 'test_recall': array([0.8220339 , 0.8       , 0.85869565]),\n",
              " 'test_runtime': 2.998,\n",
              " 'test_samples_per_second': 100.068,\n",
              " 'test_steps_per_second': 6.338}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Оценим модель на тестовых данных\n",
        "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEfVmOIUGteT"
      },
      "source": [
        "# 2. Модель с cls токенами вместе с выходами пуллер слоя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-X9ruuyrvVdD"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier2(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.n_classes = n_classes\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size*5, n_classes)\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        last_hidden_state, hidden_states = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=False)\n",
        "        cls_tokens = []\n",
        "        for hidden_state in hidden_states[-4:]:\n",
        "            cls_tokens.append(hidden_state[:, 0, : ])\n",
        "        pooled_output = torch.cat(cls_tokens, 1)\n",
        "        new_output = torch.cat((pooled_output, last_hidden_state[:, 0, : ]), 1) # добавили\n",
        "        print(new_output.shape)\n",
        "        output = self.drop(new_output)\n",
        "        logits = self.out(output)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.n_classes), labels.view(-1))\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GckP3qsDva2K",
        "outputId": "e087baa4-6a30-41b9-86be-2a7dc8547f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model2 = SentimentClassifier2(len(class_names))\n",
        "model2 = model2.to(device)\n",
        "# model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TwgMAs-VxVVt",
        "outputId": "d8eab008-7482-4788-bc0b-3c5cd5b0c38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 5400\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3840])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 06:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.147400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.093500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.100600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.130300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.043200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.091400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.019700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.927600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.839900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.833300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.842500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.996900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.868700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.822200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.985200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.736900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.724800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.818500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.020900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.839100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.775200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.762700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.866800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.744000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.960700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.812600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.757600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.822900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.845800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.728500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.719300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.768700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.797300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.775300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.716300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.737900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.767400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.749000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.946000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.837500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.677900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.651800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.835900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.902700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.850100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.748000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.964600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.857800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.710300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.777400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.750800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.961000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.561300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.546200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.458300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.588400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.664000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.750600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.572300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.571300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.490800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.634000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.618900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.557800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.537200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.541700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.663000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.631400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.549400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.623600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.644200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.524000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.405800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.619500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.637000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.537500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.485500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.717900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.591000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.557600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.615600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.562300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.449300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.563300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.491000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.497300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.514900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.379400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.570900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.625100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.550100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.466500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.416300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.452500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.465800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.593000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.346900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.528700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.543600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.504400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.381300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.420900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.395500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.434000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.332600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.506700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.534300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.657500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.534700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.473500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.506100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.603200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.469400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n",
            "torch.Size([8, 3840])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1350, training_loss=0.7056574784384834, metrics={'train_runtime': 370.9712, 'train_samples_per_second': 29.113, 'train_steps_per_second': 3.639, 'total_flos': 0.0, 'train_loss': 0.7056574784384834, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model2,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "mS9c1KaPxrNV",
        "outputId": "70446619-885a-476f-fa62-80464810971c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3840])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([12, 3840])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.76190476 0.67281106 0.78350515]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.8372093  0.64035088 0.76      ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.69902913 0.70873786 0.80851064]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.7366666666666667,\n",
              " 'eval_f1': array([0.76190476, 0.67281106, 0.78350515]),\n",
              " 'eval_loss': 0.6645860075950623,\n",
              " 'eval_precision': array([0.8372093 , 0.64035088, 0.76      ]),\n",
              " 'eval_recall': array([0.69902913, 0.70873786, 0.80851064]),\n",
              " 'eval_runtime': 2.9814,\n",
              " 'eval_samples_per_second': 100.623,\n",
              " 'eval_steps_per_second': 6.373}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "lgvQ89U0xk7k",
        "outputId": "aa06f7dc-7dc9-47f2-b22a-fdec5c9a50e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3840])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([16, 3840])\n",
            "torch.Size([12, 3840])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.84070796 0.76142132 0.88135593]\" of type <class 'numpy.ndarray'> for key \"test/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.87962963 0.70093458 0.91764706]\" of type <class 'numpy.ndarray'> for key \"test/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.80508475 0.83333333 0.84782609]\" of type <class 'numpy.ndarray'> for key \"test/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'test_accuracy': 0.8266666666666667,\n",
              " 'test_f1': array([0.84070796, 0.76142132, 0.88135593]),\n",
              " 'test_loss': 0.4969889223575592,\n",
              " 'test_precision': array([0.87962963, 0.70093458, 0.91764706]),\n",
              " 'test_recall': array([0.80508475, 0.83333333, 0.84782609]),\n",
              " 'test_runtime': 2.9904,\n",
              " 'test_samples_per_second': 100.322,\n",
              " 'test_steps_per_second': 6.354}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Оценим модель на тестовых данных\n",
        "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxCS8Mb1yvNz"
      },
      "source": [
        "# 3. Готовая модель для классификации последовательности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yuq0UWt6ymsB",
        "outputId": "849b3028-b2f5-4ac1-9d34-e4d703ad0c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertConfig\n",
        "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
        "config.num_labels = 3\n",
        "model3 = DistilBertForSequenceClassification(config)\n",
        "model3 = model3.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gn1fk9UyzGzW",
        "outputId": "0bdbeabd-6c5f-4753-8697-2793dfeb1176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 5400\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1350\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 06:11, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.116300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.143700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.166900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.096900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.101300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.161500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.114200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.107500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.124500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.094300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.093600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.152300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.205300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.156500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.056200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.054600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.132800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.041400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.124800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.193100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.114800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.062100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.994900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.023700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.942100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.928400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.861300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.958300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.898700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.948500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.947200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.079600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.892300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>1.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.903100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.899500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.899200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.978600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.904900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.999500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.972500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.055000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.981800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.935300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.852400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.998100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.824400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.785700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.784500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.857300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.858900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.923400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.834100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.880700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.748400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.824600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.883700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.851700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.767700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.797400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.831900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.796200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.873300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.794700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.849600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.731600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.751100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.735500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.725800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.641300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.830800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.749200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.907000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.851400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.759500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.866800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.755500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.860700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.788400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.767500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.765300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.719600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.670900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.637100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.754800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.795700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.894000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.802100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.689700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.840900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.724400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.792100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.681800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.785400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.685800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.678000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.650300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.732800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.736000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.707600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.677700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.514400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.696800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.722300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.788800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.727700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.751700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.912200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.891500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.655300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1350, training_loss=0.9084115173198559, metrics={'train_runtime': 371.8599, 'train_samples_per_second': 29.043, 'train_steps_per_second': 3.63, 'total_flos': 447085443456000.0, 'train_loss': 0.9084115173198559, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model3,                        # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "V0Eig_EkKs4w",
        "outputId": "25010475-5d73-4933-a383-94b3372e8f58"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.65979381 0.55454545 0.72043011]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.7032967  0.52136752 0.72826087]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.62135922 0.59223301 0.71276596]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.64,\n",
              " 'eval_f1': array([0.65979381, 0.55454545, 0.72043011]),\n",
              " 'eval_loss': 0.8411106467247009,\n",
              " 'eval_precision': array([0.7032967 , 0.52136752, 0.72826087]),\n",
              " 'eval_recall': array([0.62135922, 0.59223301, 0.71276596]),\n",
              " 'eval_runtime': 2.9867,\n",
              " 'eval_samples_per_second': 100.446,\n",
              " 'eval_steps_per_second': 6.362}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценим модель на тестовых данных\n",
        "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "nFEuYeaSKzk4",
        "outputId": "4001f1c1-0533-4284-f1c9-b5b73bb75824"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.72       0.55555556 0.76836158]\" of type <class 'numpy.ndarray'> for key \"test/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.75700935 0.50925926 0.8       ]\" of type <class 'numpy.ndarray'> for key \"test/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.68644068 0.61111111 0.73913043]\" of type <class 'numpy.ndarray'> for key \"test/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'test_accuracy': 0.68,\n",
              " 'test_f1': array([0.72      , 0.55555556, 0.76836158]),\n",
              " 'test_loss': 0.7112144231796265,\n",
              " 'test_precision': array([0.75700935, 0.50925926, 0.8       ]),\n",
              " 'test_recall': array([0.68644068, 0.61111111, 0.73913043]),\n",
              " 'test_runtime': 3.0008,\n",
              " 'test_samples_per_second': 99.973,\n",
              " 'test_steps_per_second': 6.332}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KymSGjxC2mIf"
      },
      "source": [
        "# 4. Агрегируем cls-токены для нескольких слоев, чтобы сделать предсказание класса "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WOxtmPHh2lN8"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier4(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.n_classes = n_classes\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        last_hidden_state, hidden_states = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=False)\n",
        "        cls_tokens = []\n",
        "        for hidden_state in hidden_states[-4:]:\n",
        "            cls_tokens.append(hidden_state[:, 0, : ])\n",
        "        cls_output = torch.stack(cls_tokens, 1)\n",
        "        average_cls_output = torch.mean(cls_output, 1)  # вот тут\n",
        "        output = self.drop(average_cls_output)\n",
        "        logits = self.out(output)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.n_classes), labels.view(-1))\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = SentimentClassifier4(len(class_names))\n",
        "model4 = model4.to(device)\n",
        "# model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-B_5M8nWPMN",
        "outputId": "49f26fe5-c115-4d17-d4f2-6d65fb343d84"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model4,                        # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics = compute_metrics    # metrics to evaluate\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7zhmomVhWb_o",
        "outputId": "ae4cc4ca-a106-416d-afeb-368bf58e82a0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 5400\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1350\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 06:09, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.180700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.133400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.148700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.113300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.122500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.086200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.119500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.049900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.063700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.930700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.929600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.904400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.849700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.822300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.784300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.837600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.792700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.716700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.761200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.803300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.765700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.837100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.918600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.846200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.751800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.804400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.820600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.787200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.818800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.752000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.760800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.823800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.753700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.790900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.798100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.771200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.813400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.861200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.939700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.680800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.640600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.818900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.708900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.845400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.909600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.027900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.836700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.723900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.798300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.676200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.911900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.591800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.536600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.514800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.579300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.625800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.685800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.470600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.526600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.520400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.606000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.568600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.563700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.603400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.459800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.531500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.653500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.744700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.544700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.580300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.631500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.520300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.429600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.665300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.603100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.453900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.727200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.603500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.589800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.676900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.583600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.585000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.572000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.495800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.553100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.401100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.503300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.564300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.472300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.511100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.494800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.511700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.587900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.625700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.361100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.543900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.534200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.440500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.419200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.473900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.425300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.478900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.377300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.513500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.552600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.564900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.543900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.528700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.500400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1350, training_loss=0.7146344621093185, metrics={'train_runtime': 370.2466, 'train_samples_per_second': 29.17, 'train_steps_per_second': 3.646, 'total_flos': 0.0, 'train_loss': 0.7146344621093185, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "5dBhjL-0Wi-W",
        "outputId": "8f90c0db-c6d7-4c3f-9810-84e798a34f29"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.78074866 0.69683258 0.80208333]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.86904762 0.65254237 0.78571429]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.70873786 0.74757282 0.81914894]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.7566666666666667,\n",
              " 'eval_f1': array([0.78074866, 0.69683258, 0.80208333]),\n",
              " 'eval_loss': 0.6496446132659912,\n",
              " 'eval_precision': array([0.86904762, 0.65254237, 0.78571429]),\n",
              " 'eval_recall': array([0.70873786, 0.74757282, 0.81914894]),\n",
              " 'eval_runtime': 2.9889,\n",
              " 'eval_samples_per_second': 100.37,\n",
              " 'eval_steps_per_second': 6.357}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценим модель на тестовых данных\n",
        "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "zS5sSh4KWrhg",
        "outputId": "3624f3de-a16f-4bac-e285-c6971f6fab01"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 300\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.84581498 0.7253886  0.85555556]\" of type <class 'numpy.ndarray'> for key \"test/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.88073394 0.67961165 0.875     ]\" of type <class 'numpy.ndarray'> for key \"test/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.81355932 0.77777778 0.83695652]\" of type <class 'numpy.ndarray'> for key \"test/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'test_accuracy': 0.81,\n",
              " 'test_f1': array([0.84581498, 0.7253886 , 0.85555556]),\n",
              " 'test_loss': 0.5105229020118713,\n",
              " 'test_precision': array([0.88073394, 0.67961165, 0.875     ]),\n",
              " 'test_recall': array([0.81355932, 0.77777778, 0.83695652]),\n",
              " 'test_runtime': 2.9943,\n",
              " 'test_samples_per_second': 100.19,\n",
              " 'test_steps_per_second': 6.345}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "# 5. Предсказание класса отзыва с google play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "outputs": [],
      "source": [
        "review_texts = [\"App is awkward. And even worse, convert to pdf from Chrome makes a pdf with the page url. Not the actual web page. Pointless.\",\n",
        "                \"You application tends to be non responsive buffering to too long. I keep crossing and reopening it to use.\",\n",
        "                \"I have been using acrobat from Adobe since 2007 now I use it on my phone as well as my laptop or computer. It's great software for everything a home office needs to get the job done right.\"]\n",
        "true_labels = [0, 1, 2]\n",
        "labels_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "# 1, 3, 5 звёзд"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5Ue9pEDKHmFo",
        "outputId": "dd16a4ae-d218-4664-ecf7-c07dca6c3541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 3\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 01:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review text: App is awkward. And even worse, convert to pdf from Chrome makes a pdf with the page url. Not the actual web page. Pointless.\n",
            "Sentiment  : negative\n",
            "True sentiment  : negative\n",
            "Review text: You application tends to be non responsive buffering to too long. I keep crossing and reopening it to use.\n",
            "Sentiment  : neutral\n",
            "True sentiment  : neutral\n",
            "Review text: I have been using acrobat from Adobe since 2007 now I use it on my phone as well as my laptop or computer. It's great software for everything a home office needs to get the job done right.\n",
            "Sentiment  : positive\n",
            "True sentiment  : positive\n"
          ]
        }
      ],
      "source": [
        "reviews_encodings = tokenizer(review_texts, truncation=True,\n",
        "                                 padding=True, max_length=max_len)\n",
        "dataset_to_predict = GPReviewDataset(reviews_encodings, true_labels)\n",
        "\n",
        "predictions = trainer.predict(dataset_to_predict)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "for i in range(len(preds)):\n",
        "    print(f'Review text: {review_texts[i]}')\n",
        "    print(f'Sentiment  : {labels_dict[preds[i]]}')\n",
        "    print(f'True sentiment  : {labels_dict[true_labels[i]]}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HW4_tbkazkova_BertModel.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}