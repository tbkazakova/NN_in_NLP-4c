{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что делать?\n",
    "Где есть пометка # CODE писать код\n",
    "\n",
    "[Полезный туториал](http://jalammar.github.io/illustrated-word2vec/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "Они уже обработанные и токенизированные. Процесс можно посмотреть в тетрадке 1.1 Processing corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/processed_corpus.json') as f:\n",
    "    corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "второй UNK год окончательно разочаровать решить податься альфабанк\n",
      "вернуть денежный средство лицевой счёт либо зачесть счёт погашение кредит\n",
      "притом ситуация решиться участие течение сутки заявить\n",
      "мой ##число летний жизнь это самый неповоротливый работник банк который видеть\n",
      "везде написать вклад принимать очередь это\n"
     ]
    }
   ],
   "source": [
    "for text in corpus[:5]:\n",
    "    print(' '.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вернуть денежный средство лицевой счёт либо зачесть счёт погашение кредит'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вернуть',\n",
       " 'денежный',\n",
       " 'средство',\n",
       " 'лицевой',\n",
       " 'счёт',\n",
       " 'либо',\n",
       " 'зачесть',\n",
       " 'счёт',\n",
       " 'погашение',\n",
       " 'кредит']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуйте разделение предложения на примеры методом CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbow_split(tokens, window, pad_token='PAD'):\n",
    "    \n",
    "    splits = []\n",
    "    \n",
    "    for n in range(len(tokens)):\n",
    "            left_context = tokens[np.maximum(n - window, 0):n]\n",
    "            left_context = ([pad_token] * (window - len(left_context))) + left_context\n",
    "            central_word = tokens[n]\n",
    "\n",
    "            right_context = tokens[n + 1:n + window + 1]\n",
    "            right_context = right_context + ([pad_token] * (window - len(right_context)))\n",
    "\n",
    "            splits.append((left_context, central_word, right_context))\n",
    "        \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Левый контекст: ['PAD', 'PAD']\n",
      "Центральное слово: вернуть\n",
      "Правый контекст: ['денежный', 'средство']\n",
      "\n",
      "Левый контекст: ['PAD', 'вернуть']\n",
      "Центральное слово: денежный\n",
      "Правый контекст: ['средство', 'лицевой']\n",
      "\n",
      "Левый контекст: ['вернуть', 'денежный']\n",
      "Центральное слово: средство\n",
      "Правый контекст: ['лицевой', 'счёт']\n",
      "\n",
      "Левый контекст: ['денежный', 'средство']\n",
      "Центральное слово: лицевой\n",
      "Правый контекст: ['счёт', 'либо']\n",
      "\n",
      "Левый контекст: ['средство', 'лицевой']\n",
      "Центральное слово: счёт\n",
      "Правый контекст: ['либо', 'зачесть']\n",
      "\n",
      "Левый контекст: ['лицевой', 'счёт']\n",
      "Центральное слово: либо\n",
      "Правый контекст: ['зачесть', 'счёт']\n",
      "\n",
      "Левый контекст: ['счёт', 'либо']\n",
      "Центральное слово: зачесть\n",
      "Правый контекст: ['счёт', 'погашение']\n",
      "\n",
      "Левый контекст: ['либо', 'зачесть']\n",
      "Центральное слово: счёт\n",
      "Правый контекст: ['погашение', 'кредит']\n",
      "\n",
      "Левый контекст: ['зачесть', 'счёт']\n",
      "Центральное слово: погашение\n",
      "Правый контекст: ['кредит', 'PAD']\n",
      "\n",
      "Левый контекст: ['счёт', 'погашение']\n",
      "Центральное слово: кредит\n",
      "Правый контекст: ['PAD', 'PAD']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = cbow_split(sample_text, window=2)\n",
    "for sample in splits:\n",
    "    print('Левый контекст:', sample[0])\n",
    "    print('Центральное слово:', sample[1])\n",
    "    print('Правый контекст:', sample[2], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['PAD', 'PAD'], 'вернуть', ['денежный', 'средство']),\n",
       " (['PAD', 'вернуть'], 'денежный', ['средство', 'лицевой']),\n",
       " (['вернуть', 'денежный'], 'средство', ['лицевой', 'счёт']),\n",
       " (['денежный', 'средство'], 'лицевой', ['счёт', 'либо']),\n",
       " (['средство', 'лицевой'], 'счёт', ['либо', 'зачесть']),\n",
       " (['лицевой', 'счёт'], 'либо', ['зачесть', 'счёт']),\n",
       " (['счёт', 'либо'], 'зачесть', ['счёт', 'погашение']),\n",
       " (['либо', 'зачесть'], 'счёт', ['погашение', 'кредит']),\n",
       " (['зачесть', 'счёт'], 'погашение', ['кредит', 'PAD']),\n",
       " (['счёт', 'погашение'], 'кредит', ['PAD', 'PAD'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected\n",
    "\n",
    "```python\n",
    "[(['PAD', 'PAD'], 'вопрос', ['почему', 'например']),\n",
    " (['PAD', 'вопрос'], 'почему', ['например', 'китайский']),\n",
    " (['вопрос', 'почему'], 'например', ['китайский', 'японский']),\n",
    " (['почему', 'например'], 'китайский', ['японский', 'UNK']),\n",
    " (['например', 'китайский'], 'японский', ['UNK', 'PAD']),\n",
    " (['китайский', 'японский'], 'UNK', ['PAD', 'PAD'])]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['PAD', 'PAD', 'PAD'], 'вернуть', ['денежный', 'средство', 'лицевой']),\n",
       " (['PAD', 'PAD', 'вернуть'], 'денежный', ['средство', 'лицевой', 'счёт']),\n",
       " (['PAD', 'вернуть', 'денежный'], 'средство', ['лицевой', 'счёт', 'либо']),\n",
       " (['вернуть', 'денежный', 'средство'], 'лицевой', ['счёт', 'либо', 'зачесть']),\n",
       " (['денежный', 'средство', 'лицевой'], 'счёт', ['либо', 'зачесть', 'счёт']),\n",
       " (['средство', 'лицевой', 'счёт'], 'либо', ['зачесть', 'счёт', 'погашение']),\n",
       " (['лицевой', 'счёт', 'либо'], 'зачесть', ['счёт', 'погашение', 'кредит']),\n",
       " (['счёт', 'либо', 'зачесть'], 'счёт', ['погашение', 'кредит', 'PAD']),\n",
       " (['либо', 'зачесть', 'счёт'], 'погашение', ['кредит', 'PAD', 'PAD']),\n",
       " (['зачесть', 'счёт', 'погашение'], 'кредит', ['PAD', 'PAD', 'PAD'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_split(sample_text, window=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected\n",
    "\n",
    "```python\n",
    "[(['PAD', 'PAD', 'PAD'], 'вопрос', ['почему', 'например', 'китайский']),\n",
    " (['PAD', 'PAD', 'вопрос'], 'почему', ['например', 'китайский', 'японский']),\n",
    " (['PAD', 'вопрос', 'почему'], 'например', ['китайский', 'японский', 'UNK']),\n",
    " (['вопрос', 'почему', 'например'], 'китайский', ['японский', 'UNK', 'PAD']),\n",
    " (['почему', 'например', 'китайский'], 'японский', ['UNK', 'PAD', 'PAD']),\n",
    " (['например', 'китайский', 'японский'], 'UNK', ['PAD', 'PAD', 'PAD'])]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вернуть денежный средство лицевой счёт либо зачесть счёт погашение кредит'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуйте разделение предложения на примеры методом Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram_split(tokens, window):\n",
    "    \n",
    "    splits = []\n",
    "\n",
    "    for n in range(len(tokens)):\n",
    "            left_context = tokens[np.maximum(n - window, 0):n]\n",
    "            central_word = tokens[n]\n",
    "            right_context = tokens[n + 1:n + window + 1]\n",
    "            context = left_context + right_context\n",
    "            for word in context:\n",
    "                splits.append((word, central_word))\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Контекст: денежный\n",
      "Центральное слово: вернуть\n",
      "\n",
      "Контекст: средство\n",
      "Центральное слово: вернуть\n",
      "\n",
      "Контекст: вернуть\n",
      "Центральное слово: денежный\n",
      "\n",
      "Контекст: средство\n",
      "Центральное слово: денежный\n",
      "\n",
      "Контекст: лицевой\n",
      "Центральное слово: денежный\n",
      "\n",
      "Контекст: вернуть\n",
      "Центральное слово: средство\n",
      "\n",
      "Контекст: денежный\n",
      "Центральное слово: средство\n",
      "\n",
      "Контекст: лицевой\n",
      "Центральное слово: средство\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: средство\n",
      "\n",
      "Контекст: денежный\n",
      "Центральное слово: лицевой\n",
      "\n",
      "Контекст: средство\n",
      "Центральное слово: лицевой\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: лицевой\n",
      "\n",
      "Контекст: либо\n",
      "Центральное слово: лицевой\n",
      "\n",
      "Контекст: средство\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: лицевой\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: либо\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: зачесть\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: лицевой\n",
      "Центральное слово: либо\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: либо\n",
      "\n",
      "Контекст: зачесть\n",
      "Центральное слово: либо\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: либо\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: зачесть\n",
      "\n",
      "Контекст: либо\n",
      "Центральное слово: зачесть\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: зачесть\n",
      "\n",
      "Контекст: погашение\n",
      "Центральное слово: зачесть\n",
      "\n",
      "Контекст: либо\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: зачесть\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: погашение\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: кредит\n",
      "Центральное слово: счёт\n",
      "\n",
      "Контекст: зачесть\n",
      "Центральное слово: погашение\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: погашение\n",
      "\n",
      "Контекст: кредит\n",
      "Центральное слово: погашение\n",
      "\n",
      "Контекст: счёт\n",
      "Центральное слово: кредит\n",
      "\n",
      "Контекст: погашение\n",
      "Центральное слово: кредит\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = skipgram_split(sample_text, window=2)\n",
    "\n",
    "for sample in splits:\n",
    "    print('Контекст:', sample[0])\n",
    "    print('Центральное слово:', sample[1], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('денежный', 'вернуть'),\n",
       " ('средство', 'вернуть'),\n",
       " ('вернуть', 'денежный'),\n",
       " ('средство', 'денежный'),\n",
       " ('лицевой', 'денежный'),\n",
       " ('вернуть', 'средство'),\n",
       " ('денежный', 'средство'),\n",
       " ('лицевой', 'средство'),\n",
       " ('счёт', 'средство'),\n",
       " ('денежный', 'лицевой'),\n",
       " ('средство', 'лицевой'),\n",
       " ('счёт', 'лицевой'),\n",
       " ('либо', 'лицевой'),\n",
       " ('средство', 'счёт'),\n",
       " ('лицевой', 'счёт'),\n",
       " ('либо', 'счёт'),\n",
       " ('зачесть', 'счёт'),\n",
       " ('лицевой', 'либо'),\n",
       " ('счёт', 'либо'),\n",
       " ('зачесть', 'либо'),\n",
       " ('счёт', 'либо'),\n",
       " ('счёт', 'зачесть'),\n",
       " ('либо', 'зачесть'),\n",
       " ('счёт', 'зачесть'),\n",
       " ('погашение', 'зачесть'),\n",
       " ('либо', 'счёт'),\n",
       " ('зачесть', 'счёт'),\n",
       " ('погашение', 'счёт'),\n",
       " ('кредит', 'счёт'),\n",
       " ('зачесть', 'погашение'),\n",
       " ('счёт', 'погашение'),\n",
       " ('кредит', 'погашение'),\n",
       " ('счёт', 'кредит'),\n",
       " ('погашение', 'кредит')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram_split(sample_text, window=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected\n",
    "\n",
    "```python\n",
    "[('почему', 'вопрос'),\n",
    " ('например', 'вопрос'),\n",
    " ('вопрос', 'почему'),\n",
    " ('например', 'почему'),\n",
    " ('китайский', 'почему'),\n",
    " ('вопрос', 'например'),\n",
    " ('почему', 'например'),\n",
    " ('китайский', 'например'),\n",
    " ('японский', 'например'),\n",
    " ('почему', 'китайский'),\n",
    " ('например', 'китайский'),\n",
    " ('японский', 'китайский'),\n",
    " ('UNK', 'китайский'),\n",
    " ('например', 'японский'),\n",
    " ('китайский', 'японский'),\n",
    " ('UNK', 'японский'),\n",
    " ('китайский', 'UNK'),\n",
    " ('японский', 'UNK')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('денежный', 'вернуть'),\n",
       " ('средство', 'вернуть'),\n",
       " ('лицевой', 'вернуть'),\n",
       " ('вернуть', 'денежный'),\n",
       " ('средство', 'денежный'),\n",
       " ('лицевой', 'денежный'),\n",
       " ('счёт', 'денежный'),\n",
       " ('вернуть', 'средство'),\n",
       " ('денежный', 'средство'),\n",
       " ('лицевой', 'средство'),\n",
       " ('счёт', 'средство'),\n",
       " ('либо', 'средство'),\n",
       " ('вернуть', 'лицевой'),\n",
       " ('денежный', 'лицевой'),\n",
       " ('средство', 'лицевой'),\n",
       " ('счёт', 'лицевой'),\n",
       " ('либо', 'лицевой'),\n",
       " ('зачесть', 'лицевой'),\n",
       " ('денежный', 'счёт'),\n",
       " ('средство', 'счёт'),\n",
       " ('лицевой', 'счёт'),\n",
       " ('либо', 'счёт'),\n",
       " ('зачесть', 'счёт'),\n",
       " ('счёт', 'счёт'),\n",
       " ('средство', 'либо'),\n",
       " ('лицевой', 'либо'),\n",
       " ('счёт', 'либо'),\n",
       " ('зачесть', 'либо'),\n",
       " ('счёт', 'либо'),\n",
       " ('погашение', 'либо'),\n",
       " ('лицевой', 'зачесть'),\n",
       " ('счёт', 'зачесть'),\n",
       " ('либо', 'зачесть'),\n",
       " ('счёт', 'зачесть'),\n",
       " ('погашение', 'зачесть'),\n",
       " ('кредит', 'зачесть'),\n",
       " ('счёт', 'счёт'),\n",
       " ('либо', 'счёт'),\n",
       " ('зачесть', 'счёт'),\n",
       " ('погашение', 'счёт'),\n",
       " ('кредит', 'счёт'),\n",
       " ('либо', 'погашение'),\n",
       " ('зачесть', 'погашение'),\n",
       " ('счёт', 'погашение'),\n",
       " ('кредит', 'погашение'),\n",
       " ('зачесть', 'кредит'),\n",
       " ('счёт', 'кредит'),\n",
       " ('погашение', 'кредит')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram_split(sample_text, window=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected\n",
    "\n",
    "```python\n",
    "[('почему', 'вопрос'),\n",
    " ('например', 'вопрос'),\n",
    " ('китайский', 'вопрос'),\n",
    " ('вопрос', 'почему'),\n",
    " ('например', 'почему'),\n",
    " ('китайский', 'почему'),\n",
    " ('японский', 'почему'),\n",
    " ('вопрос', 'например'),\n",
    " ('почему', 'например'),\n",
    " ('китайский', 'например'),\n",
    " ('японский', 'например'),\n",
    " ('UNK', 'например'),\n",
    " ('вопрос', 'китайский'),\n",
    " ('почему', 'китайский'),\n",
    " ('например', 'китайский'),\n",
    " ('японский', 'китайский'),\n",
    " ('UNK', 'китайский'),\n",
    " ('почему', 'японский'),\n",
    " ('например', 'японский'),\n",
    " ('китайский', 'японский'),\n",
    " ('UNK', 'японский'),\n",
    " ('например', 'UNK'),\n",
    " ('китайский', 'UNK'),\n",
    " ('японский', 'UNK')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "\n",
    "for text in corpus:\n",
    "    for token in text:\n",
    "        if token not in word2index:\n",
    "            word2index[token] = len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13076"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1282, 8436, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word2index[tok] if tok in word2index else word2index['UNK'] for tok in 'мама мыть рама'.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Dataset\n",
    "В торче есть очень удобная читалка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# игрушечный датасет\n",
    "# 121535 примера, 4 фичи, 3 класса\n",
    "some_data_x = np.random.rand(121535, 4)\n",
    "some_data_y = np.random.randint(3, size=(121535,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7323884 , 0.5276922 , 0.68471796, 0.30834704],\n",
       "       [0.01649276, 0.63853503, 0.11454044, 0.72496185],\n",
       "       [0.1221261 , 0.69116564, 0.04852857, 0.54147502],\n",
       "       [0.9539036 , 0.29368606, 0.86682618, 0.689017  ],\n",
       "       [0.39373833, 0.01355538, 0.75614069, 0.0947331 ],\n",
       "       [0.12860973, 0.84919984, 0.73181016, 0.03198506],\n",
       "       [0.88522817, 0.12202667, 0.07854838, 0.31357897],\n",
       "       [0.75633805, 0.15315535, 0.63438039, 0.71954921],\n",
       "       [0.40961842, 0.02126046, 0.41304357, 0.33143529],\n",
       "       [0.09465356, 0.59529499, 0.98753837, 0.29996706]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соверешенно игрушечный, просто цифры\n",
    "some_data_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 2, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_x, data_y):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # Нужно обязательно определить эту функцию\n",
    "        # Должна возвращать размер датасета\n",
    "        \n",
    "        return len(self.data_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Еще нужно определить этот метод\n",
    "        # То есть как мы будем доставать наши данные по индексу\n",
    "        \n",
    "        return self.data_x[idx], self.data_y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataset = ToyDataset(some_data_x, some_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.01649276, 0.63853503, 0.11454044, 0.72496185]), 1),\n",
       " (array([0.26535081, 0.79539776, 0.20545179, 0.89166755]), 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_dataset[1], some_dataset[467]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_loader = DataLoader(some_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, tensor([[0.0544, 0.3067, 0.8479, 0.3706],\n",
       "         [0.8216, 0.9340, 0.3568, 0.2657],\n",
       "         [0.3753, 0.2608, 0.9757, 0.2195],\n",
       "         [0.5666, 0.8403, 0.2892, 0.1181],\n",
       "         [0.4563, 0.7304, 0.5078, 0.2475],\n",
       "         [0.9333, 0.8359, 0.3175, 0.5819],\n",
       "         [0.0299, 0.9155, 0.4873, 0.8069],\n",
       "         [0.4106, 0.4684, 0.2475, 0.3836],\n",
       "         [0.9321, 0.3926, 0.1515, 0.9994],\n",
       "         [0.8016, 0.9786, 0.6077, 0.9027],\n",
       "         [0.1731, 0.0285, 0.1257, 0.2432],\n",
       "         [0.5070, 0.2361, 0.2144, 0.7892],\n",
       "         [0.5522, 0.2654, 0.8144, 0.2564],\n",
       "         [0.5361, 0.3578, 0.0710, 0.9702],\n",
       "         [0.5348, 0.8032, 0.7232, 0.4851],\n",
       "         [0.9380, 0.3104, 0.3577, 0.6232]], dtype=torch.float64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in some_loader:\n",
    "    break\n",
    "    \n",
    "len(x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in some_loader:\n",
    "    pass\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# почему 13?\n",
    "# потому что количество наших данных нацело не делится на 16\n",
    "# и поэтому последний батч меньше 16-ти\n",
    "len(some_dataset) % 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# А зачем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_x, data_y):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # Нужно обязательно определить эту функцию\n",
    "        # Должна возвращать размер датасета\n",
    "        \n",
    "        return len(self.data_x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_pow_features(x, n=2):\n",
    "        \n",
    "        return np.concatenate([x, x ** n]) \n",
    "    \n",
    "    @staticmethod\n",
    "    def add_log_features(x):\n",
    "        \n",
    "        return np.concatenate([x, np.log(x)]) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Еще нужно определить этот метод\n",
    "        # То есть как мы будем доставать наши данные по индексу\n",
    "        \n",
    "        x = self.data_x[idx]\n",
    "        \n",
    "        # внутри датасета мы можем делать все что угодно с нашими данными\n",
    "        # например выше определим функции, которые добавляют степенные фичи\n",
    "        x = self.add_pow_features(x, n=2)\n",
    "        x = self.add_pow_features(x, n=3)\n",
    "        # и еще возьмем логарифмические фичи\n",
    "        x = self.add_log_features(x)\n",
    "        \n",
    "        y = self.data_y[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_dataset = ToyDataset(some_data_x, some_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_loader = DataLoader(dataset=toy_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in toy_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.3239e-01,  5.2769e-01,  6.8472e-01,  ..., -3.8355e+00,\n",
       "         -2.2725e+00, -7.0592e+00],\n",
       "        [ 1.6493e-02,  6.3854e-01,  1.1454e-01,  ..., -2.6915e+00,\n",
       "         -1.3001e+01, -1.9298e+00],\n",
       "        [ 1.2213e-01,  6.9117e-01,  4.8529e-02,  ..., -2.2163e+00,\n",
       "         -1.8154e+01, -3.6808e+00],\n",
       "        ...,\n",
       "        [ 9.1260e-02,  9.5344e-01,  7.1120e-01,  ..., -2.8607e-01,\n",
       "         -2.0448e+00, -5.3048e+00],\n",
       "        [ 2.3092e-01,  2.7162e-01,  2.0998e-01,  ..., -7.8200e+00,\n",
       "         -9.3644e+00, -3.2180e+01],\n",
       "        [ 6.8165e-02,  8.9406e-01,  2.6295e-01,  ..., -6.7187e-01,\n",
       "         -8.0148e+00, -1.0080e+01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заметим, что мы сразу получаем торчовый формат данных\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 0, 2, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1,\n",
       "        2, 1, 2, 0, 1, 0, 1, 2, 2, 0, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 2, 1, 2, 1,\n",
       "        1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 2, 0, 0, 0, 2, 2, 0, 2, 1, 2, 1, 0, 0, 0, 1, 2, 1, 2, 2, 1, 1, 0,\n",
       "        0, 1, 2, 2, 0, 1, 2, 1, 0, 0, 2, 1, 2, 0, 0, 0, 1, 2, 2, 1, 1, 2, 1, 0,\n",
       "        0, 2, 0, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Если вы ничего здесь не понимаете, то вернитесь в конец первой домашки, там все объясняется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(32, 16),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(16, 8),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(8, 3))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1222634315490723"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    prediction = model(x.float())\n",
    "\n",
    "    loss = criterion(prediction, y)\n",
    "    \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Боевые датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 corpus,\n",
    "                 word2index,\n",
    "                 window=2,\n",
    "                 unk_token='UNK',\n",
    "                 pad_token='PAD',\n",
    "                 collect_verbose=True):\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.word2index = word2index\n",
    "        self.index2word = {value: key for key, value in self.word2index.items()}\n",
    "        self.window = window\n",
    "\n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = self.word2index[self.unk_token]\n",
    "\n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = len(self.word2index)\n",
    "\n",
    "        self.collect_verbose = collect_verbose\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        self.collect_data()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "\n",
    "    def _split_function(self, tokenized_text):\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        for n in range(len(tokenized_text)):\n",
    "            left_context = tokenized_text[np.maximum(n - self.window, 0):n]\n",
    "            left_context = ([self.pad_index] * (self.window - len(left_context))) + left_context\n",
    "\n",
    "            central_word = tokenized_text[n]\n",
    "\n",
    "            right_context = tokenized_text[n + 1:n + self.window + 1]\n",
    "            right_context = right_context + ([self.pad_index] * (self.window - len(right_context)))\n",
    "\n",
    "            splits.append((left_context + right_context, central_word))\n",
    "\n",
    "        return splits\n",
    "\n",
    "    def indexing(self, tokenized_text):\n",
    "\n",
    "        return [self.word2index[token] if token in self.word2index else self.unk_index for token in tokenized_text]\n",
    "\n",
    "    def collect_data(self):\n",
    "\n",
    "        corpus = tqdm(self.corpus, disable=not self.collect_verbose)\n",
    "\n",
    "        for tokenized_text in corpus:\n",
    "            indexed_text = self.indexing(tokenized_text)\n",
    "            cbow_examples = self._split_function(indexed_text)\n",
    "\n",
    "            self.data.extend(cbow_examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        context, central_word = self.data[idx]\n",
    "\n",
    "        context = torch.Tensor(context).long()\n",
    "\n",
    "        return context, central_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мы будем учить модель Skipgram\n",
    "Реализуйте читалку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 corpus,\n",
    "                 word2index,\n",
    "                 window=2,\n",
    "                 unk_token='UNK',\n",
    "                 collect_verbose=True):\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.word2index = word2index\n",
    "        self.index2word = {value: key for key, value in self.word2index.items()}\n",
    "        self.window = window\n",
    "\n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = self.word2index[self.unk_token]\n",
    "\n",
    "        self.collect_verbose = collect_verbose\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        self.collect_data()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "\n",
    "    def _split_function(self, tokenized_text):\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        for n in range(len(tokenized_text)):\n",
    "                left_context = tokenized_text[np.maximum(n - self.window, 0):n]\n",
    "                central_word = tokenized_text[n]\n",
    "                right_context = tokenized_text[n + 1:n + self.window + 1]\n",
    "                lr_context = left_context + right_context\n",
    "                for word in lr_context:\n",
    "                    splits.append((word, central_word))\n",
    "\n",
    "        return splits\n",
    "\n",
    "    def indexing(self, tokenized_text):\n",
    "\n",
    "        return [self.word2index[token] if token in self.word2index else self.unk_index for token in tokenized_text]\n",
    "\n",
    "    def collect_data(self):\n",
    "\n",
    "        corpus = tqdm(self.corpus, disable=not self.collect_verbose)\n",
    "\n",
    "        for tokenized_text in corpus:\n",
    "            indexed_text = self.indexing(tokenized_text)\n",
    "            skipgram_examples = self._split_function(indexed_text)\n",
    "\n",
    "            self.data.extend(skipgram_examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        context, central_word = self.data[idx]\n",
    "        \n",
    "        return context, central_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можете положить SkipgramDataset в отдельный файлик, например word2vec_utils и относительным импортом достать его \n",
    "#from .word2vec_utils import SkipgramDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:04<00:00, 23262.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = SkipgramDataset(corpus, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([973, 163, 476, 724,  89])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1612, 4466,   89,   25,  122])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512]), torch.Size([512]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, pad_index):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        if pad_index > 0:\n",
    "            vocab_size += 1\n",
    "        \n",
    "        self.in_embedding = torch.nn.Embedding(num_embeddings=vocab_size, \n",
    "                                               embedding_dim=embedding_dim,\n",
    "                                               padding_idx=pad_index)\n",
    "        \n",
    "        self.out_embedding = torch.nn.Linear(in_features=embedding_dim,\n",
    "                                             out_features=vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.in_embedding(x).sum(dim=-2)\n",
    "        x = self.out_embedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мы будем учить модель Skipgram\n",
    "Реализуйте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "class SkipGram(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_embedding = torch.nn.Embedding(num_embeddings=vocab_size, \n",
    "                                               embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.out_embedding = torch.nn.Linear(in_features=embedding_dim,\n",
    "                                             out_features=vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.in_embedding(x)\n",
    "        x = self.out_embedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from word2vec_utils import SkipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размерность эмбеддинга\n",
    "# маленькая, чтобы мы могли недолго поучить ворд2век и увидеть результаты\n",
    "EMBEDDING_DIM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipGram(vocab_size=len(word2index), embedding_dim=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 13076])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "\n",
    "# aka loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишите обучалку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████▉| 2982912/2983124 [09:22<00:00, 5303.63it/s, loss=9.12]\n",
      "Epoch 2: 100%|█████████▉| 2982912/2983124 [09:04<00:00, 5481.87it/s, loss=8.15]\n",
      "Epoch 3: 100%|█████████▉| 2982912/2983124 [11:24<00:00, 4360.08it/s, loss=7.62]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "losses = []\n",
    "\n",
    "for n_epoch in range(epochs):\n",
    "\n",
    "    try:\n",
    "\n",
    "        progress_bar = tqdm(total=len(dataset_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "        for x, y in dataset_loader:\n",
    "\n",
    "            optimizer.zero_grad()  #обнуляем градиенты\n",
    "            preds_proba = model(x) #прогоняем данные через модель\n",
    "            loss = criterion(preds_proba, y) #считаем значение функции потерь  \n",
    "            loss.backward() #считаем градиенты  \n",
    "            optimizer.step() #обновляем веса \n",
    "                        \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            progress_bar.set_postfix(loss=np.mean(losses[-100:]))\n",
    "\n",
    "            progress_bar.update(x.shape[0])\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        progress_bar.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b3a8ab5d0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3gVZfbA8e9JA5JQQgudgDQB6QLKKmBDiqKuutZVV5e17NrW9Ycd3V0XdXXXtaxdrIANyyKIIBFEQOlNRErovSdA6vn9MZNwk9xU7tybm3s+z5OHmXfamUm4577vzPuOqCrGGGMiW1SoAzDGGBN6lgyMMcZYMjDGGGPJwBhjDJYMjDHGYMnAGGMMlgxMOYnI9SLyXQnLrhaRacGOqaoSkbYikh7odY3xkiUDU0BEfiUi34vIQRHZJyJzROTUsrZT1fdU9bwKHKepiLwqIttEJF1E1ovIOBHpdGJnUHEi0sqNIf9HRSTDZ/6Miu5TVderamKg160oEXlXRLLc89gnItNEpIMXxzLhz5KBAUBE6gD/A54D6gPNgUeBzAAfpwHwPRAPnAHUBnoB3wLnlrBNTCBj8KWqm1Q1Mf/HLe7uUzbbTzzRXsXjgcfd82oJ7APe8LeSl9fYhAdLBiZfBwBVHa+quap6VFWnqeoyfyuLyFMi8p2I1C3ahOR+u77d/ca/x103/2/tLuAQcK2qrlPHAVV9U1Wfc7dPcfdxo4hsAr5xyz8UkR1uzWWWiHTxOeY4EXlRRKa434TniEgTEfm3iOwXkdUi0rMyF8b9hv2CiEwVkQzgDBG5UESWiMhhEdkkIg/5rN9ORNRn/jsRedStdR1291O/ouu6y29wj7dHRO4XkS0iMqisc1DVDGA80NXdz99EZKKIjBeRw8A1IlJTRP4jIttFZKuIPCMicT7HvsQ950MislZEznPL64nIm+52W0Tksfzft4h0cH9XB92Y33fLo9xj7XKXLRORzpX5/ZjAsGRg8q0BckXkLREZKiJJ/lZy/xO/CnQDzlPVgyXs72KgD863/pHA79zyc4BJqppXjpgGAicDQ9z5KUB7oDGwCHivyPqXAw8CDXFqNHPd9RoCHwHPlOOYJbkKp6ZU291vOnANUBe4ALhDREaUsf11QDKQANxd0XVF5BTgP8AVODW3RkCT8gQvIrXd/S72Kb4YeN89h4nAwzi/s25AT2AAcJ+7/ek4tYo/A/WAwcBGdz/vAkeBk9zthwM3uMv+DkwGkoAWwAtu+VCgP87vM8k9p33lORfjDUsGBgBVPQT8ClDgVWC3iHwuIsk+q8XifLusD1ygqkdK2eUTqrpPVTcB/waudMsbAjvyV3K/YR9wvwUXvQk9RlUzVPWoG+MbqnpYVTOBMUB3Eanrs/4kVV2oqseAScAxVX1bVXNxPuwqVTPw2fdcVc1T1UxV/UZVV7jzS4EJOMmrJK+r6i/uNfsQ6FGJdS8DPlXV791r8GA54h4tIgdwkn0NjidlgO9U9Qv3HI4CV+Nc892qugt4DLjWXfdG4FVVneGuv1lVfxaR5sDZwF2qekRVd+D8vq9wt8sGUoCmqnpMVef4lNcBOgGo6ip3WxMilgxMAVX9SVWvV9UWOM0JzXD+Y+drh/Mt/1FVzSpjd5t9pje6+wLYCzT1OebnqloPp/kojsIK9iEi0SIyVkTWicghIM1d1NBn/Z0+00f9zJ/IjVrf80FEThORVBHZLSIHgZuKxFKU7wfdkTJiKWndZr5xuE0/+8uIe6yq1lPVpqp6kapu8Fm2uci6TTn+bR93urk73RJY52f/rXGSzE43qR/A+faf/yXizzhfIhaIyHIRuc6NfRrwEvBfd9uX3NqLCRFLBsYvVV0NjMNtY3b9hFP9nyIiHcvYRUuf6VbANnd6BnCRzz2EUsPwmb4KJxGdg9OskeKWSzn2EwhFh/edAHwMtFTVusBrQYhlO05TCwAikoDTxFJZRc9pO86He75WwFZ3ejNOM1BRm3ESVn036dRT1Tqq2g1AVber6k2q2hS4DXhFRNq4y/6tqr1w/sY6U3rTmfGYJQMDgIh0EpE/i0gLd74lTtPOPN/1VHU8cD8wXUT8fTjk+4uIJLn7uQOnmQacdvsk4B0ROUkctSm92QSctvpMnJpFPPB4xc4w4GoD+1T1mIj053iziJc+xEmk/d0bu48FeP/jgYdFpKGINAIewrkfAPA6cJOIDHbvG7UQkY6quhnnSbB/ikgdd1k7ETkTQEQud5uSAA7gJKBcEenr/sQAGUAWkBvg8zEVYMnA5DsM9APmi/PEzDxgBU41vxBVfQvng+gbEUkpYX+fAQuBJTg3EF93t92Dc+PwGPCde9wlOB+ut5QS39s4zRZbgVUUSVIhcAvwD/dJnPuBD7w+oPtk1104SWEbTmLcS+Ae/30UWAosB5YB84F/uMf+Hvg9zg3sg8BMjtf+rsG50b0Kp9nqQ47f2O4H/Oj+TX0C3ObeR6qH8zdxAKfJbzvwrwCdh6kEsZfbmEBzH5Vsr6prQx1LdSZO35ADQGv3G7oxlWY1A2PCiPv0VbyIJAJPA4ssEZhAsGRgTHi5GKeJaAvOTfQrS13bmHKyZiJjjDFWMzDGGANhNzhVw4YNNSUlpVLbZmRkkJCQENiAPBRO8YZTrGDxeimcYoXwivdEYl24cOEeVW1U4gqqGlY/vXv31sqaOXNmpbcNhXCKN5xiVbV4vRROsaqGV7wnEiuwQEv5bLVmImOMMZYMjDHGWDIwxhiDJQNjjDFYMjDGGIMlA2OMMVgyMMYYQ4Qlg23pecxdtzfUYRhjTJUTUcng/u+OcuWroR4G3xhjqp6ISgbGGGP8i5hkkJ2bVzA9bs4GjmbZG/aMMSZf2A1UV1lPT1tTMD3mi1XM37CPQ8eyad+4Nnec3Z6khLgQRmeMMaEVMTWDr1buKDQ/ZcUO5qzdy7jv0xj8dCoHjmQBMG3lDjbuzQhFiMYYEzIRkww27Cn5A/7AkWxGvjCHp75azah3FjLwqVSmr9pJyujJrN2Vzr6MLJ6cupqU0ZODGLExxgRPxDQTlWXj3iO8MHNdwfx9k5YDcM4z3xZab/Yvu2mYWIOTm9YJanzGGOOliKkZ1Iip2KnuPpzpt/za139g6LOzyczJ5Vh2LkezcnnksxWkZ+YEIkxjjAmJiKkZ3H52e5766ueA7e+UMdPIyskjPi6aI1m5rN+TwTs39gvY/o0xJpgipmZw66CTArq/rBznUdUj7iOqs3/ZA8CPafvYfvAoAP/30TLa3f9lQI9rjDFeiJiagYh4foxrXpvPd2udpPDujf2YuGAzAHl5ytrd6XRIrg3A3vRMGiTWKLSt8+o5iIryPk5jjCkqYmoGwZCfCACueX1+wfSpf5/Oef+axXMzfmHysu30/tt0fkzbBziJYtmWA4z/YTNt7/+SXYeOBT1uY4yJmJoBwNgzajF69tGgH3dvhtOH4emv1/Db01oDcNlLczmtbQNOO6kBz3x9vEPchj0ZNK5Ts9g+Un/eRbN6tQpqF8YYE0gRlQyaJERRp2YM7RoncuBoNut3B79z2dtzNxZMz12/l7nrC4+i+sWybfRr26DYdte/+SMAaWOHexugMSYiRVQyAFg2Zkih+RVbDzLiue9CFE1x787bRL82Dbige7NQh2KMiSCe3jMQkTtEZIWIrBSRO/0sHyQiB0VkifvzsJfx+NO1eV1e/W2fYB+2VH8av5g/vr+I0bOP8PiXP5H6865Qh2SMqeY8qxmISFfg90BfIAuYKiKTVfWXIqvOVtURXsVRHud2Tub5q3oyZ+0e+rVpQLcWdTnr6W/L3tBD/1u2HYBXZq3nlVnrC8rzh8RIGzucxZv2s3HvES7q2TwkMRpjqg8vm4lOBuap6hEAEfkWuBh40sNjVtqIbs0Y0S18mmbu/mAJnyzaCsCZHRqRkZlDy/rxIY7KGBOuvGwmWgGcKSINRCQeGAa09LPeaSKyVESmiEgXD+OpkH5t6hdMjzqzbcH0useHhSKcYvITAUCvv37NGU/OZNGm/faeBmNMpYiqerdzkRuB24B0YBVwVFXv8lleB8hT1XQRGQY8q6rt/exnFDAKIDk5ufeECRMqFU96ejqJiYnlXj8rV/loTRYXt4/jYKZyLEdJqRvN4/OPEh8jZOYqPRrHMH51VqXi8UpcNPx9QC0a1hJ+3JlL78bRRHvcma2i1zbULF7vhFOsEF7xnkisgwcPXqiqJd4g9TQZFDqQyOPAFlV9sZR10oA+qrqnpHX69OmjCxYsqFQMqampDBo0qFLblmTtrsOc88ysgO4zEEYP7cSanYf5ZNFW/nxuB/50drEcG1BeXFsvWbzeCadYIbziPZFYRaTUZOD100SN3X9bAZcA44ssbyLuOBEi0teNZ2/R/VRl7RrX5uu7zqRP6yQA/nZRV9LGDufpy7rzx8HtQhbX2CmrC5qSpq/eRWZObsELfIwxpiiv+xl8LCINgGzgNlXdLyI3A6jqS8ClwC0ikgMcBa7QYFVVAqh9cm3aJyeyYON+8odA+nXvFgBc0bclP20/zMAOjejw4JSQxLd08wE6PjgVgMUPnUtSQhxHs3KpERNlYyEZYwCPk4GqnuGn7CWf6eeB572MIVhio51KVmxU4cpWi6R4WiQ5T/kM7tiImT/vDnpsvq59Yz7jf9+fU8ZM45Jezeneoh4nNUrk1DZJfLp4K5f3aRmUQf2MMVVLxPVA9so9QzpSIyaq1Gf+37yhLwePZJO6Zhd3TFhSaNmTl3YjLjqKOycuKWHrwFix9RCnjJkGOE8k+T6VBJBYI5bh3Zp6GoMxpuqxUUsDpE7NWB4Y3pm4Mt6oVjc+lpE9mjP73sEsH3NeQfnlfVpWic5j9360NNQhGGNCwJJBiLSsH0/tmrHMvncw8+8/u6B89r2DuTCE4xJlZOWSMnoyny7eWvbKxphqw5JBiLWsH0+yz5DVLevH858re9Ku8fFniT+59XRaNwhu7+I7Jy5h+qqdhOH9fGNMJVgyqKKm3z2QcecnkDZ2OL1aJfHtXwZzw4AUAJY8fG5QYrjp7QW89O16jmXnkpun5OUp+zLs8VRjqiO7gRxGHrmgC49c0IVj2cEbcuKJqat5Yupqzu2cTNtGCbz87Xp+uP9svy/gMcaEL6sZhKE8t+mmVmw0aWOH88JVvTw/5terdvLyt87oqX0fn8GOg/Z6TmOqE0sGYSjK7QcwsEMjAL+Pgn58y+mextD/HzPIzs0rmD+Wozz11WqycvJK2coYU1VZMghDNWOjSb1nEP++okdB2ed/HFAw/cJVvejdOonRQzt5Gseuw5nMWuN0ovt8XTYvzFzHxB83eXpMY4w37J5BmEppmFBovluLeoDTdJRfU7h54En0bp3E+t3pfL1qJ9N/Cuwb0waM/aZYWVauPX1kTDiymkE18sgFnQvVEABOTanPb05tRfvk2kGJYdHG/UE5jjEmsCwZVCM3DGhT4od+jTJ6RgfK5OXbg3IcY0xgWTKIEFf1awXADQNSeOSCzp4eKyMzp2D6v6nrCt7bbIypuiwZRIjGtWuy6KFzeWh4Z05pXheAC3yGvbjaTRaBsHZXOsu2HOBYdi5PTF0dsP0aY7xjN5AjSP2EOAD6pNQveK/Bc1f2LFj+3vzAPAk08oU5xcomLd7CxT2ddzzMXL2Lvm3qk1DD/vyMqSqsZhChktzE4OuvF3X17Hh3TVzKwaPZpO3J4IZxP9L/HzPIzbMnj4ypKiwZmALX9m/NX4Z09Gz/c9bu4Yul2wA4fCyHF2eu9exYxpiKsXq6KeTWQSdxVd9WPPz5yoIP7oDt+71FheY37MkI6P6NMZVnNQNTiIiQlBDHHWe39/xYX67YTmZO8AbdM8aUzJKB8atd40Ta+PRy9uJx1GPZeXR8cCoAN731I7e+tzDgxzDGlI8lA1OiSbeeTsfk2qx6bAg3DGjDme7AeIH22ZKtTP9pF18u3wHA5n1HyMm1Ae+MCSZLBqZE9eLj+OquM4mPc24tvf27vp4c544JSwqmdx0+xhlPzuRvk3/y5FjGGP8sGZgq5cCRbADenptmj54aE0SWDEyFREeJp/s/71+zAMhTeOizFZ4eyxhznCUDUyEtkmr5Lb+5ew0u690ioMd6P0A9oo0xZbNkYCpkwqj+PHtFD5rXc5LCoI7OTeWa0XB+1yYBP549empMcFgyMBXStG4tRvZozjf3DGT1X8+nSZ2aANSMEc4+OZlPbxtQxh4qpuODU5m3fi/qvvf5gwWb+Wb1zoAewxhjycBUUo2YaGrGRvPwBZ3552Xd6Zjk/Cn1aFmP2fcOpmV9/81JlXHFK/P4x5TVzP5lN/d+tIzfjVsQsH0bYxyWDMwJiY+L4dLeLRA5fmO5Zf14bj8rsD2YX5m1nmtf/6FQ2cptB1m7Kz2gxzEmUtnYRMYTXj8UOubzlYz7Pg2AtLHDPT6aMdWf1QyMJ6LdmsJQD24qAwWJwBgTGJYMjCcu6N6M605rzeMXnxLqUIwx5WDNRMYTcTFRPDrSu5fl+JOZk8uxrDzqxscG9bjGVAdWMzCeW/jgOYXmbx54UkD3P3nZdtbvTufa136g+2PTWLxpf0D3b0wk8LRmICJ3AL8HBHhVVf9dZLkAzwLDgCPA9aq6qNiOTFhrkFiD92/qR+M6NWjXuDaqSt1asTwxdXVA9n/b+4X/ZC5+8fuCm8pz1+2lVYP4gk5yxhj/PKsZiEhXnETQF+gOjBCRos8bDgXauz+jgP96FY8JrdPbNaRd49qA8wKdWwYFtnZQkitfncfgf6YG5VjGhDMvm4lOBuap6hFVzQG+BS4uss5I4G11zAPqiUhTD2MyEeLtuWkF01k59m4EY8riZTPRCuDvItIAOIrTFFS062hzYLPP/Ba3bLuHcZkI8PBnK6ld056PMKa8JH/MF092LnIjcBuQDqwCjqrqXT7LJwP/UNXv3PkZwL2qurDIfkbhNCORnJzce8KECZWKJz09ncTExEptGwrhFG9lYn107lG6NoimX9MYHpxz1KPIHOPOTyg0H07XFsIr3nCKFcIr3hOJdfDgwQtVtU9Jyz396qSqrwOvA4jI4zjf/H1tAVr6zLcAtvnZzyvAKwB9+vTRQYMGVSqe1NRUKrttKIRTvJWJ1Xf1nPobGPPFqoDGVPhYg9h64GjBjeRwurYQXvGGU6wQXvF6Gaunj5aKSGP331bAJcD4Iqt8DvxWHP2Bg6pqTUQR6PoBbTzd/9QVOxgw9htm/rzL0+MYE6687mfwsYisAr4AblPV/SJys4jc7C7/ElgPrAVeBW71OB5Thf3zsu68e2M/2jUOfJV9+dYDAKzYcjDg+zamOvC6megMP2Uv+Uwrzj0FY7jUfVPa9LsHkjJ6ckD3/ersDQA8/fUahp7SBC/vlRkTjqwHsokIvo+XnvPMLGZsyvG73tQVO5j9y+5ghWVMlWHJwFRJT13azdP9v/tTFtm5eazddZj2D3zJ5n1HALj53YXF3ptgTCSwZGCqpMv6HH/IrG2jBCaO6h/wY7R/YArnPDOL7FzltdnreWXWuoAfw5hwYb1yTJXXMbk2/do28PQYb83d6On+janqrGZgqqz8PgF3n9sh6MfOy7MbzCayWDIwVdY9Q5wk0LJ+fEHZ4I6NuP70FM+P/dGiov0jjanerJnIVFkX92zBxT1bFMz//LfziYmKIkpg8ab9LPWwz8C9Hy3j4p7NiY2270smMthfugkbNWKiiY4SRKTQDWav/OXDpWTm5Hp+HGOqAksGJixd3a8V8+47m5qx3v0Jf7pkG799/QcWbdrPlv1HPDuOMVWBJQMTlkSEJnVrUrumt+87nr9hH5e8+D2/emKmp8cxJtQsGZiwdmH3ZkE7lg1hYaozSwYmrN0/7GTeuL7EIdoDqs19XwblOMaEgiUDE9aio4SzOiWz6rEhJMV722QEsGTzAc+PYUwoWDIw1UJ8XAwf3ny658e56IU5nh/DmFCwZGCqDS/eg+BPyujJHMlyRj1dsvkAm/Ye4Y4Ji3nksxVBOb4xXrBOZ8ZUwn9mrGX00E7FagqPjuwaooiMOTFWMzDVUsfk2p7u/6Vv1wX8BTzGhJLVDEy1Mv3ugdSpFcPz36zl552HQx2OMWHDagamWmnXOJHGtWsyskdzwEkOwbTz0LGgHs+YQLFkYKql3q2TSBs7nHaNE1n6yHlBO26/x2fw2ZKtBfOHj2Vz98QlHDyaHbQYjKkMSwam2qtbK5ZFD50btOPdMWEJ2w4cBeCt79P4ZPFWe4uaqfIsGZiIUD8hjoEdGgXteKM/WQ5A/ggWizdZZzVTtVkyMBEjSpx/X7/O++ErZq3ZTV6e8r9l2wH4ft1ejmXnsmrbIc+PbUxlWDIwESNKnGwQrDdavjxrfaEnmv7v42UM+89s9qZnBicAYyqgXMlARE4SkRru9CARuV1E6nkbmjGBJQXJQPlNxzjeu6mfp8d7YurqQvPz1+8Dio9vtCBtHy9/a/cUTGiVt2bwMZArIu2A14E2wPueRWWMBy7p5Txu2rlpHYa2iWVAu4ZBPf4O97HTG99aUKj80pfm8o8pq/1tYkzQlLfTWZ6q5ojIxcC/VfU5EVnsZWDGBNqwU5qSNnY4AKH+Hj5rzW7GfZ/GN6t3hTgSYxzlrRlki8iVwHXA/9wy78cLNsZjs+8dzHWntaZ2zeB2xv/tGz9YIjBVSnmTwQ3AacDfVXWDiLQB3vUuLGOCo2X9eB4d2ZV5950d6lDYuDcj1CGYCFauZKCqq1T1dlUdLyJJQG1VHetxbMYETUKNGNLGDi9oRgqFgU+lhuzYxpT3aaJUEakjIvWBpcCbIvKMt6EZE1q1awR/HMcVWw8ydspqBoz9JujHNpGtvM1EdVX1EHAJ8Kaq9gbO8S4sY0Knd+skAG47q13Qjz3iue946dt1bD1wlLw8ZffhTPLyFFXlyamreejTFcxdtzfocZnqr7xffWJEpClwOfCAh/EYE3L5PZXzNEi900rwxNTVvDxrPUO7NmFgkvLibOcZqHfmbQxpc5apnspbM3gM+ApYp6o/ikhb4BfvwjImdO4fdjIdkhM5pXndkMbx8qz1AExZsSNovaZN5CrvDeQPVbWbqt7izq9X1V+XtZ2I3CUiK0VkhYiMF5GaRZZfLyK7RWSJ+3NT5U7DmMDp2SqJaXcNJCEE9wxKMmWDDYFtvFXeG8gtRGSSiOwSkZ0i8rGItChjm+bA7UAfVe0KRANX+Fl1oqr2cH9eq/AZGBMBZm/NKVb2/vxNvJi6tmB+f0YWN7z5A/sysoIZmqkmyttM9CbwOdAMaA584ZaVJQaoJSIxQDywrTJBGhMKJzVMDHUIJXph5lrun7ScJ6f+XFD25vdpzPx5N7ePt8EBTMWJluMmmYgsUdUeZZX52e4O4O/AUWCaql5dZPn1wD+A3cAa4C5V3exnP6OAUQDJycm9J0yYUGbM/qSnp5OYWHX/gxcVTvGGU6xQvnhz8pSbph1h5EmxfLbueDPN5R1i+WBN1Wm2GXd+Apk5yuM/HGPjobyCslCpjn8LVcWJxDp48OCFqlri+O3lTQbTgXHAeLfoSuAGVS2x26bbOe1j4DfAAeBD4CNVfddnnQZAuqpmisjNwOWqelZpsfTp00cXLFhQ2iolSk1NZdCgQZXaNhTCKd5wihUqHu+uQ8fo+/gMvh99Fs3q1eLuD5bwyaKtZW8YJAM7NOLbNbsL5kP5tFF1/1sIpROJVURKTQblbSb6Hc5jpTuA7cClOENUlOYcYIOq7lbVbOAT4HTfFVR1r6rmD+7+KtC7nPEYE1SN69QkbexwmtWrBUCTOjXL2CK4fBOBMZVR3qeJNqnqharaSFUbq+pFOB3QSrMJ6C8i8eIMJH828JPvCm7fhXwXFl1uTFV1Zd9WoQ7BmIA6kTed3V3aQlWdD3wELAKWu8d6RUQeE5EL3dVudx89XYrz5NH1JxCPMUHTsn48H99yetkrGhMmTiQZSFkrqOojqtpJVbuq6rWqmqmqD6vq5+7y+1S1i6p2V9XBqmpv+DBho3frJF64qleow/DrjgmLWbL5AFk5eYXKM3Ny8Xef8Mvl25n446ZghWeqoBNJBtYn0kS8Yac04YM/nBbqMIr5bMk2LnphDh0enMIzX68BID0zh44PTuVf04sPHnDre4v4v4+XBztMU4WUmgxE5LCIHPLzcxinz4ExEU1E6NumfqjDKNV/Zjgf/geOOJ3RPl64JZThmCqq1P72qlo7WIEYY7wV4nH3TBV3Is1ExpgwtPXA0VCHYKogSwbGBMCgjo0A+N+ffsUF3Z0W1OtOax3KkIypkKozLKMxYezN608FnHsIzeo5HdKa1K3FtLvO5Lx/zQplaAD0f3wG0VGFHwBUVd6bv4mRPez2n7FkYExAOP0qHb/p05Lx8zdxQfemtEiKJy46iqzcvFK29t6OQ8cKzX/w42ZaNYjnwU9XsHDj/hBFZaoSayYyJsDaNkpk2ZghtEiKB+CGASmhDciPez9extGsXIBCQ15/tHALKaMnM2+9vVoz0lgyMMZj9w07mQeGnRzqMEo0f8PxD/57PlwKwJTl20MVjgkRSwbGBIGU2V8/+PKfKjqWXbwJa+W2Q8xdZ7WDSGLJwJgI9eCnK0pctmDjfq58dR6j3q7ccPEm/FgyMMaUaNqqnaEOwQSJJQNjguDsk5MBGHNBZx4e0RmApPjYUIZUbsu3HATgm9U7C4a0MNWPJQNjgqBNwwTSxg7n+gFtuKa/0xlt9NBOBctD+Wayslzw/HccOJLF78Yt4PdvL+CSF+fw39R1oQ7LBJglA2OCLC4mirSxw7m0d8tQh1Ju+f0kNuzJYNGmAzwxtfho83/5cCntH/gy2KGZALFkYEyIRFXBJ4xKkpHp9EnYk368mShl9GRWbD1Y8FTShwu3kJ1ro+GFK0sGxoSIlPC8aesG8UGOpGx3Tlzit3zEc98xYOw3hcpunZ4RjJBMgNlwFMaE2IB2DQCYdOvp7DqcydmdGnPre4uq1JM8SzcfKPe6R3I8DMR4xmoGxoRQ6j2DePW3fQDo2SqJIV2aEBMdxStuWacm4fFKkb3pmYXmZ/y0k5wQj8dkKsaSgTEhlNIwgfg4/xX0FY8O4bM/DgCrqgQAABcGSURBVODUlKQgR1Vxvf82vdD8jW8t4NkZxV+vaaouSwbGVFGJNWKoERNNq/oJoQ6lUtL2HuFYdi5bDxxlQdq+UIdjymD3DIyp4n5/Zhs+XhR+7y3+Yuk2vli6rWA+vy9FXp6iUOz9Cia0rGZgTBXXqUkd/jM4njPaNwx1KCckK8e5h3DmUzM56X6nP0JenvLcjF/Yn2E9m0PNkoExYaBODWHUmW1DHcYJ6fDgFAC27D/+Dubv1+3l6a/XcP+k5aEKy7gsGRgTJlqH6b2DkrwzN41rXp8PwJGsXKau2F7QgQ2cdyv46+lsvGHJwJgw0aoKdkarqM37jhRMT1ywudCym99dxIXPfQc472f+aOEWGwMpiCwZGBNG8juohasznpxZMK1+Rq7Y6947mLR4a7BCMi5LBsaEkfdu6h82HdHKsnHv8VpC0aGx7/5gabDDiXiWDIwJYxf1aBbqECotPfP4uBU/7ThcMP1jAPskbNybQUamjY9RHpYMjAkz+c0rT1/WnX9f0bOg/Ks7zyzorXxh9/BKEvmPnQJc9tLcQsv2Z2TR5eGpLNx4PElMX7WTT8rR92LgU6lc/dr8wAVajVkyMCZMdWlep9B8R5/mo/wX6BT1uwFtPI3JCz+m7SMjK5enp60pKLvp7QXlbkpaUoFB9iKZJQNjwkz/tvUBqFcrrsR11N/dWeCPZ7XzJCYv5eY55/L9ur0AfPfLnkLL96Zn8sTU1QXrmcqxZGBMmHlwRGe++fNAmtStWWyZ4AzxUNLHYv2EOJ6/qmcJS6umW95bVGg+v28CODeeH5i0gv+mruOk+7/kvfkbOeeZb0vc15GsnBITZaSzZGBMmImNjqJto0S/y25zv/mf3OR4E1LPVvUKrRPOn4WdH55aaL7HY19zODO7YP6BSStYuyvd77Yb92bQ+eGvGP/DZr/LI52nyUBE7hKRlSKyQkTGi0jNIstriMhEEVkrIvNFJMXLeIyp7gZ2aETa2OHUjY8tKJt064BC64RxLuBIVm6xsjlr9xYr+2n7IdbsPFyobN1uJ0m8Nnu9N8GFOc9GLRWR5sDtQGdVPSoiHwBXAON8VrsR2K+q7UTkCuAJ4DdexWRMJHlg2Mls2e88yz/1zjOONyGFc9WgnIY+O7tYWf75r99TvtdyLtl8gK37jxIdJZzftUlA46uKvB7COgaoJSLZQDywrcjykcAYd/oj4HkREY2Ev1ZjPPZ7n4HtOjWpU+J6v+7VIiyHyK4I30dXAf78wVKe+PUpxESX3Dhy0QtzCqb/96df0bV53ULL56/fy+FjOZzTOTmwwYaIZ8lAVbeKyD+BTcBRYJqqTiuyWnNgs7t+jogcBBoAhR4XEJFRwCiA5ORkUlNTKxVTenp6pbcNhXCKN5xiheoZb3nPZ+W2wp2wEo/tqmRU4aPDg1Po1Ti6YP7jRVuIydhFh6QokmOOFly7pbtzaJYQVawpbfa8BexpEF2o7PqpTg1j3PnlG0AwT5XH5x9jeNtYejau3Eevl3+3XjYTJeF8828DHAA+FJFrVPVd39X8bFqsVqCqrwCvAPTp00cHDRpUqZhSU1Op7LahEE7xhlOsUL3ibTp3BtsPHiv3+exbtAWWHX9Gf8y15zBi4/5inb2qm0W7Ct9vmPizMwTGuPMTC67d9aMnA8XfPd2te3cGtCvyPompzrrlve5Hs3JZ+9VUXl6ezeq/nlPB6B1e/t16eQP5HGCDqu5W1WzgE+D0IutsAVoCiEgMUBew9+MZUwFf3n4G0+8+s9zrN69Xq9C8iHBqSv1AhxU2Jv1S/MU6q3cUvvl89Wvz+WDBiT2FpFX81r2X9ww2Af1FJB6nmehsYEGRdT4HrgPmApcC39j9AmMqJikhjqSEkjugFdWvbQM+/+MAUhomcCAju+wNqrnP1mXzbDnWu/ejZTSvV4sB7Roy8cdNlT6e+G0QCT0v7xnMF5GPgEVADrAYeEVEHgMWqOrnwOvAOyKyFqdGcIVX8RhjjuvWwul7UKdmbBlrRoZxczYw5otVZa63cttB/pu6ju/W7ilz3aKq+tdcT/sZqOojqtpJVbuq6rWqmqmqD7uJAFU9pqqXqWo7Ve2rqvYAsDEh8sfB4TdURaCUJxGA84FeNBF0feSrQk8elUV8KgYpoyfTbcxX5d7WS9YD2RgDwD1DOpI2dniow6jS/H25T8/MYcnmA+Tk5hUaLvujhVtIGT2ZY9m55OZpwUB7gtPXIyfXedz10LGqMcS2JQNjTCGDOzYCoGFiXNi/WS3QivZX8HXPh0vp8sjxb/n/+tr58N99OJPpP+3kjTkbAMjIymXs1NW0e2CKt8FWkNedzowxYea/1/Rm9+FMWtaP51h2Lk9O/bnggyzSPfP1mhKXfbrE6VN7LDuXmrHRBT297/1oWbEniV7+tvwt4nvSM9lx8FixTm+BZsnAGFNIzdhoWtaPL5h++ILOlgwqYPKy7UxZsYNtB48BMHd98bGTKmLos7PZfTjT8yY8ayYyxpTp171aFEyf36X6j9NzIv784VKm/7SzQtukjJ7MO3PT2LzvSLFluw9nBiiy0lkyMMaU6clLuxVM/+fK8HofQrh46LOVnPHkTNbv9j8Et9csGRhjyhQddfx5yLiYKLq3KLv9umNy7TLXMcXtOOQ0L209cJR5J9jEVBF2z8AYU2Ef3XI6ny7eyo9p+5i1Zk/BB5ivwZ0aM6hjI16eZd2HKmK/2yt88D9TS316KdCsZmCMKZebftWmYDo2OorL+rTkyUu78/kfnZfniED7xoXfwHbfsJODGmN1cNv7zms+iyYCrxODJQNjTLk8OKKz3yda6rvjIglwQfdmBeVFR/405Tdt5Y5iZX+fXL5e0pVlycAYc0Lyn6AXkUIjoo7s0cz/BqZMo95ZWKzsrbkbPT2m3TMwxgSEAJf0as76X1ZzzdABiFTN0TmNf1YzMMacEN/ROEWEU5vE0LRurZI38OO3p7UG4CKrTYSMJQNjzAnJH2qhvBWB//3pV8XKurtDalttInQsGRhjTkiU+wGeP4RFWbo2r8u1/VsXKiu47wC8eHWvAEZXvXj57i+7Z2CMOSGx0VG8dE1verWqV+p6M+8ZxC63P8JjI7vwzjznhuhV/VodX0lg2ClNPYs13Hn5fhyrGRhjTtj5XZvQuE7NUtdp0zCBfm2dIbF9m4Mev/gUT7/xVic/bM/1bN+WDIwxIXe8mcj/PYM1fxsavGCqsJeWeTdonTUTGWOqjPwKw+x7B5ORlcM/v/qZO8/pQFyMfW/1miUDY0zIDenShPfnb+JPZznvYc6/Gf3adaeGMqyIYsnAGOOpLs3qsHLboWLl//5ND05uWgeAurVi+fS2AaXup33jRH7ZFZrhnSOB1b2MMZ56//f9mXLHGcXKL+rZnI4VGL/oCz/9E24/u32xwfFM5VgyMMZ4qm6t2IIawImoGRvN7wa0KVR2aa8WfH33wBPet7FkYIwJI/cP68TUO4/XMop2WH7y190wlWPJwBgTNmKio+jUpA5Xux3VEms4tz3r1oplRLemXH5qS1qVsye0KcxuIBtjws6YC7twy6CTSHLfpbD0kfMKlmkF+umu+dtQOjw4JeDxhSOrGRhjwk5sdBQtkvzXAPI7M1/Tv1Wh8n9ccgo9yxgyI5JZMjDGVCs3DzwJgNvPal+o/Mq+rTip0fEnj74ffVapI61e0qu5J/FVVZYMjDHVyjX9W5M2dji14qJLXa9ZvVrERJWcDc7q1DjQoVVplgyMMRHLd8C8QR0bFVo2olsz6tSMnNuqlgyMMdVSeW8jd0yKYkiXZMbd0LfYsln3Di5W9vVdZ55gZFWTJQNjTLV3akoSAPcN7VRs2X39avHytX38blf0zWv92tSnXTXt8WzJwBhTLcVFH/9469nKSQYNEmvQu3VSidusfHRIofn8XJBYI4a0scOZ+IfTqu2rOS0ZGGOqpZqx0bxxvfON3/ftaR/fcjppY4f73SahRuF7BPmv9IyEl+94lgxEpKOILPH5OSQidxZZZ5CIHPRZ52Gv4jHGRJ6zOiWTNnY4PVpWrn9Bfh0gr4Rc8Pp1/puXwpFnt8pV9WegB4CIRANbgUl+Vp2tqiO8isMYYyorv0WopF7NXZvXDWI03gpWM9HZwDpV3Rik4xljTKVcf3oK53ZOBqBGjNNX4S9Dit94Bkgu4b3P//5ND09iS4j1ZLcASDDawkTkDWCRqj5fpHwQ8DGwBdgG3KOqK/1sPwoYBZCcnNx7woQJlYojPT2dxMTweRIgnOINp1jB4vVSOMUKlYv3+qkZAIw7P6Fg+plBtbg79Sh9m0Rza4+azNmazavLswIaa3yM8uI5lbu2gwcPXqiqJbZreZ4MRCQO54O+i6ruLLKsDpCnqukiMgx4VlXb+9tPvj59+uiCBQsqFUtqaiqDBg2q1LahEE7xhlOsYPF6KZxihcrFmzJ6MgBpY4cXms7IzKFGTBQx7pNM+csqYkiXZL5audPvsoRYWPlX/ze/yyIipSaDYDQTDcWpFRQ7O1U9pKrp7vSXQKyINAxCTMYYE3AJNWIKEoGviaP6l7pdfFw053dpAsBFPUoeE8nLh1qDkQyuBMb7WyAiTcR9aFdE+rrx7A1CTMYYU2mz7x3MN38u3xvWRnRrSr+2Dbj73A4FZflDIl3WuwXgjLQa7RaGqhuDpwNviEg8cC7wB5+ymwFU9SXgUuAWEckBjgJXaCQ80GuMCWstfV6gM3popxLf5ezbn+E3p7bkma/X0DCxBi3r12LxpgOM7NGcDxduQVHGXNiFBolxnH1yconH7dnYu49sT5OBqh4BGhQpe8ln+nng+aLbGWNMuMgfMrss+V/4RSClQQKLNx2gbi3n8aCWSfE0ql2Dx0Z2Lbad732J67rEBSRmfyJnSD5jjAkh3yaPv1/clRHdmnJKi7q8fG3vEl+6Uyu28DDcpQ25faIsGRhjTBDUT4gjpUE8DwzvTHxcTEFz0BD3xrGvtLHDOZadG9T4LBkYY0wQxEZHkfqX4kNil6SmT63gyUu70aZhAhlpy7wIDbBkYIwxVd7lfVoCkJrm3TFs1FJjjDGWDIwxxlgyMMYYgyUDY4wxWDIwxhiDJQNjjDFYMjDGGIMlA2OMMQTpTWeBJCK7gcq+PrMhsCeA4XgtnOINp1jB4vVSOMUK4RXvicTaWlUblbQw7JLBiRCRBaW96aeqCad4wylWsHi9FE6xQnjF62Ws1kxkjDHGkoExxpjISwavhDqACgqneMMpVrB4vRROsUJ4xetZrBF1z8AYY4x/kVYzMMYY44clA2OMMZGTDETkfBH5WUTWisjoEMXQUkRmishPIrJSRO5wy8eIyFYRWeL+DPPZ5j435p9FZEiwz0dE0kRkuRvXAresvoh8LSK/uP8mueUiIv9xY1omIr189nOdu/4vInKdB3F29Ll+S0TkkIjcWZWurYi8ISK7RGSFT1nArqWI9HZ/V2vdbSv9wtwSYn1KRFa78UwSkXpueYqIHPW5xi+VFVNJ5x3geAP2uxeRNiIy3413oohU+s30JcQ60SfONBFZ4pYH79qqarX/AaKBdUBbIA5YCnQOQRxNgV7udG1gDdAZGAPc42f9zm6sNYA27jlEB/N8gDSgYZGyJ4HR7vRo4Al3ehgwBRCgPzDfLa8PrHf/TXKnkzz+fe8AWlelawucCfQCVnhxLYEfgNPcbaYAQwMc63lAjDv9hE+sKb7rFdmP35hKOu8Axxuw3z3wAXCFO/0ScEsgYy2y/Gng4WBf20ipGfQF1qrqelXNAiYAI4MdhKpuV9VF7vRh4CegeSmbjAQmqGqmqm4A1uKcS6jPZyTwljv9FnCRT/nb6pgH1BORpsAQ4GtV3aeq+4GvgfM9jO9sYJ2qltZTPejXVlVnAfv8xHHC19JdVkdV56rzKfC2z74CEquqTlPVHHd2HtCitH2UEVNJ5x2weEtRod+9+437LOCjQMRbWqzusS4Hxpe2Dy+ubaQkg+bAZp/5LZT+Iew5EUkBegLz3aI/utXvN3yqdSXFHczzUWCaiCwUkVFuWbKqbgcnwQGNq1C8AFdQ+D9TVb22ELhr2dydLlruld/hfBvN10ZEFovItyJyhltWWkwlnXegBeJ33wA44JMIvby2ZwA7VfUXn7KgXNtISQb+2k5D9kytiCQCHwN3quoh4L/ASUAPYDtONRFKjjuY5zNAVXsBQ4HbROTMUtYNebxuW+6FwIduUVW+tqWpaHzBvMYPADnAe27RdqCVqvYE7gbeF5E6wYypBIH63QfzPK6k8BeZoF3bSEkGW4CWPvMtgG2hCEREYnESwXuq+gmAqu5U1VxVzQNexamuQslxB+18VHWb++8uYJIb2063mppfXd1VVeLFSVqLVHWnG3eVvbauQF3LLRRutvEkbveG9Qjgard5Are5Za87vRCn3b1DGTGVdN4BE8Df/R6cZroYP+cRMO7+LwEm+pxD0K5tpCSDH4H27hMBcTjNCJ8HOwi3PfB14CdVfcanvKnPahcD+U8ZfA5cISI1RKQN0B7nplFQzkdEEkSkdv40zg3EFe6x8p9iuQ74zCfe34qjP3DQraZ+BZwnIkluVf08t8wLhb5ZVdVr6yMg19JddlhE+rt/Z7/12VdAiMj5wP8BF6rqEZ/yRiIS7U63xbmW68uIqaTzDmS8Afndu0lvJnCpl/EC5wCrVbWg+Seo17ayd8TD7Qfn6Yw1OJn1gRDF8CucqtwyYIn7Mwx4B1juln8ONPXZ5gE35p/xeTokGOeD81TFUvdnZf5xcNpQZwC/uP/Wd8sFeMGNaTnQx2dfv8O5UbcWuMGjeOOBvUBdn7Iqc21xktR2IBvnm92NgbyWQB+cD7x1wPO4IwwEMNa1OG3q+X+7L7nr/tr9+1gKLAIuKCumks47wPEG7Hfv/l/4wb0GHwI1AhmrWz4OuLnIukG7tjYchTHGmIhpJjLGGFMKSwbGGGMsGRhjjLFkYIwxBksGxhhjsGRgIoSIpLv/pojIVUE65p0iEu8z/6W4I30aU9VYMjCRJgUISDJwO4SV9n/oTpy+DwCo6jBVPRCIYxsTaJYMTKQZC5whztjwd4lItDjj9P/oDmj2B3DGjxKRGSKySJwx40e65SnivI/iRZxOQC1F5L8iskCcd1Q86q53O9AMmCkiM92yNBFp6E7fLSIr3J87i+z7VXdf00SkVv7+RGSVG+OEIF8zEwGs05mJCCKSrqqJIjIIZ4z7EW75KKCxqv5NRGoAc4DLcHraxqvqIfcDfB7OUACtcd4hcLo6Q0sjIvVVdZ87bMAM4HZVXSYiaTg9h/e466Xh9BptjdPbtD9OT+P5wDXAfpwern1UdYmIfIAzHMK7IrINaKOqmSJSz2oYJtCsZmAi3Xk4YwAtwflQboDzoS/A4yKyDJiOMzxwsrvNxvxE4LpcRBYBi4EuOC9PKc2vgEmqmqGq6cAnOEMXA2xQ1SXu9EKcZi1whlR4T0SuwRkx1JiAiil7FWOqNQH+pKqFBs4TkeuBRkBvVc12v9XXdBdn+KzXBrgHOFVV94vIOJ/1SjtmSTJ9pnOBWu70cJw3ZF0IPCQiXfT4+PrGnDCrGZhIcxjnlaP5vgJuEWdocUSkgztCa11gl5sIBuM07fhTByc5HBSRZJwhtEs6Vr5ZwEUiEu8e62JgdkkBuzepW6rqTOBeoB6QWPapGlN+VjMwkWYZkCMiS3Ha7Z/FaYpZ5A4FvBvnNYHvAV+IyAKcETpX+9uZqi4VkcU4I0uux7nnkO8VYIqIbFfVwT7bLHJrED+4Ra+p6mJx3n7nTzTwrojUxalV/MvuGZhAsxvIxhhjrJnIGGOMJQNjjDFYMjDGGIMlA2OMMVgyMMYYgyUDY4wxWDIwxhgD/D9GUfxfJDF3ZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('SkipGram Training Process')\n",
    "plt.xlabel('Itearations')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка, что хоть что-то выучилось\n",
    "assert np.mean(losses[-1000:]) < 7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.in_embedding.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(embedding_matrix, token2id, word1, word2):\n",
    "    \n",
    "    i1 = token2id[word1]\n",
    "    i2 = token2id[word2]\n",
    "    \n",
    "    v1, v2 = embedding_matrix[i1], embedding_matrix[i2]\n",
    "    \n",
    "    v1_n = v1.div(v1.norm(keepdim=True))\n",
    "    v2_n = v2.div(v2.norm(keepdim=True))\n",
    "    \n",
    "    similarity = torch.dot(v1_n, v2_n).item()\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Косинусная близость\n",
    "От 0 до 1, где 0 - вектора абсолютно разные, где 1 - идентичные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42159315943717957"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(embedding_matrix, word2index, 'день', 'месяц')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4944082498550415"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(embedding_matrix, word2index, 'минута', 'месяц')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1272643655538559"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(embedding_matrix, word2index, 'сотрудник', 'сотрудница')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18784090876579285"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(embedding_matrix, word2index, 'вклад', 'перевод')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Косинусная близость слова \"день\" к случайному выбраному слову \"мера\" равна 0.400'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_word = random.choice(list(word2index.keys()))\n",
    "sim = cos_sim(embedding_matrix, word2index, 'день', random_word)\n",
    "'Косинусная близость слова \"день\" к случайному выбраному слову \"{}\" равна {:.3f}'.format(random_word, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "\n",
    "for text in corpus:\n",
    "    for token in text:\n",
    "        if token in freq:\n",
    "            freq[token] += 1\n",
    "        else:\n",
    "            freq[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq = [(k, freq[k]) for k in sorted(freq, key=freq.get, reverse=True)]\n",
    "top_sorted_freq = sorted_freq[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 13076 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 13076 samples in 9.285s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 13076\n",
      "[t-SNE] Computed conditional probabilities for sample 13076 / 13076\n",
      "[t-SNE] Mean sigma: 1.211600\n",
      "[t-SNE] Computed conditional probabilities in 0.847s\n",
      "[t-SNE] Iteration 50: error = 98.8429871, gradient norm = 0.0000005 (50 iterations in 9.029s)\n",
      "[t-SNE] Iteration 100: error = 98.8439255, gradient norm = 0.0000000 (50 iterations in 4.417s)\n",
      "[t-SNE] Iteration 100: gradient norm 0.000000. Finished.\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 98.843925\n",
      "[t-SNE] Iteration 150: error = 5.7523575, gradient norm = 0.0000000 (50 iterations in 4.568s)\n",
      "[t-SNE] Iteration 150: gradient norm 0.000000. Finished.\n",
      "[t-SNE] KL divergence after 150 iterations: 5.752357\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, init='pca', random_state=42, verbose=2)\n",
    "reduced = tsne.fit_transform(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = [a for a,_ in top_sorted_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = [word2index[word] for word in top_words]\n",
    "x_coords = [coords[0] for coords in reduced[inds]]\n",
    "y_coords = [coords[1] for coords in reduced[inds]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x, y, word) in zip(x_coords, y_coords, top_words):\n",
    "#    plt.scatter(x, y, marker='.', color='blue')\n",
    "#    plt.text(x+0.01, y+0.01, word, fontsize=9)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка\n",
    "1. Вы добрались сюда и все работает, значит уже получили 7 баллов.\n",
    "2. 8 баллов - Взяли корпус для оценка качества эмбеддингов [здесь](https://rusvectores.org/static/testsets/ru_simlex965_tagged.tsv). Описание к нему [здесь](https://arxiv.org/pdf/1801.06407.pdf). Его английская версия для понимания, того что же это такое [тут](https://fh295.github.io/simlex.html). Если в кратце - он похож а гугл аналогии, просто иначе составлен. Определили качество своих эмбеддингов. Как качество измерить? Можете все значения отнормировать (привести к 1) и затем считать MSE между тем что у вас и что в оригинале.\n",
    "3. 9 баллов - Поставили эксперименты, поменяли любые параметры, хоть корпус увеличили или как то почистили. Показали метрики до и после. После должно быть лучше, иначе это все еще 8 баллов.\n",
    "4. 10 баллов - удивили своим подходом (или просто удивили) пока делили на 9 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Average Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>авария_NOUN</td>\n",
       "      <td>бедствие_NOUN</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>август_NOUN</td>\n",
       "      <td>месяц_NOUN</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>авиация_NOUN</td>\n",
       "      <td>полет_NOUN</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>автомобиль_NOUN</td>\n",
       "      <td>гудок_NOUN</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>автомобиль_NOUN</td>\n",
       "      <td>автострада_NOUN</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>яблоко_NOUN</td>\n",
       "      <td>солнце_NOUN</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>961</td>\n",
       "      <td>ядро_NOUN</td>\n",
       "      <td>пушка_NOUN</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>язык_NOUN</td>\n",
       "      <td>горло_NOUN</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>ярд_NOUN</td>\n",
       "      <td>дюйм_NOUN</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>964</td>\n",
       "      <td>яростный_ADJ</td>\n",
       "      <td>злой_ADJ</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             # Word1            Word2  Average Score\n",
       "0        авария_NOUN    бедствие_NOUN           6.15\n",
       "1        август_NOUN       месяц_NOUN           2.85\n",
       "2       авиация_NOUN       полет_NOUN           6.77\n",
       "3    автомобиль_NOUN       гудок_NOUN           1.85\n",
       "4    автомобиль_NOUN  автострада_NOUN           1.23\n",
       "..               ...              ...            ...\n",
       "960      яблоко_NOUN      солнце_NOUN           0.15\n",
       "961        ядро_NOUN       пушка_NOUN           2.77\n",
       "962        язык_NOUN       горло_NOUN           1.38\n",
       "963         ярд_NOUN        дюйм_NOUN           2.62\n",
       "964     яростный_ADJ         злой_ADJ           7.46\n",
       "\n",
       "[965 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlex = pd.read_csv('ru_simlex965_tagged.tsv', sep=\"\\t\")\n",
    "simlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex['# Word1'] = simlex['# Word1'].apply(lambda x: x.split('_')[0])\n",
    "simlex['Word2'] = simlex['Word2'].apply(lambda x: x.split('_')[0])\n",
    "simlex['my_res'] = 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for index, row in simlex.iterrows():\n",
    "    if row['# Word1'] in word2index.keys() and row['Word2'] in word2index.keys():\n",
    "        simlex['my_res'][index] = cos_sim(embedding_matrix, word2index, row['# Word1'], row['Word2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "compare = simlex.loc[simlex['my_res']!='UNK']\n",
    "# нормализуем\n",
    "compare['Average Score'] = (compare['Average Score']-compare['Average Score'].min())/(compare['Average Score'].max()-compare['Average Score'].min())\n",
    "compare['my_res'] = (compare['my_res']-compare['my_res'].min())/(compare['my_res'].max()-compare['my_res'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16010252475712206"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare['loss2'] = (compare['Average Score'] - compare['my_res'])**2\n",
    "MSE = compare['loss2'].mean()\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Average Score</th>\n",
       "      <th>my_res</th>\n",
       "      <th>loss2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>август</td>\n",
       "      <td>месяц</td>\n",
       "      <td>0.287298</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.208008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>автомобиль</td>\n",
       "      <td>гудок</td>\n",
       "      <td>0.186492</td>\n",
       "      <td>0.524222</td>\n",
       "      <td>0.114062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>автомобиль</td>\n",
       "      <td>такси</td>\n",
       "      <td>0.418347</td>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.000741228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>автомобиль</td>\n",
       "      <td>велосипед</td>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.442023</td>\n",
       "      <td>0.0917544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>автомобиль</td>\n",
       "      <td>мост</td>\n",
       "      <td>0.115927</td>\n",
       "      <td>0.450641</td>\n",
       "      <td>0.112033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>952</td>\n",
       "      <td>юбилей</td>\n",
       "      <td>год</td>\n",
       "      <td>0.271169</td>\n",
       "      <td>0.947396</td>\n",
       "      <td>0.457282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td>юбилей</td>\n",
       "      <td>дата</td>\n",
       "      <td>0.667339</td>\n",
       "      <td>0.774933</td>\n",
       "      <td>0.0115765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>954</td>\n",
       "      <td>юг</td>\n",
       "      <td>север</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520079</td>\n",
       "      <td>0.270482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>юрист</td>\n",
       "      <td>банкир</td>\n",
       "      <td>0.115927</td>\n",
       "      <td>0.478899</td>\n",
       "      <td>0.131748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>язык</td>\n",
       "      <td>горло</td>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.642719</td>\n",
       "      <td>0.253619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        # Word1      Word2  Average Score    my_res        loss2\n",
       "1        август      месяц       0.287298  0.743378     0.208008\n",
       "3    автомобиль      гудок       0.186492  0.524222     0.114062\n",
       "5    автомобиль      такси       0.418347  0.445572  0.000741228\n",
       "7    автомобиль  велосипед       0.139113  0.442023    0.0917544\n",
       "9    автомобиль       мост       0.115927  0.450641     0.112033\n",
       "..          ...        ...            ...       ...          ...\n",
       "952      юбилей        год       0.271169  0.947396     0.457282\n",
       "953      юбилей       дата       0.667339  0.774933    0.0115765\n",
       "954          юг      север       0.000000  0.520079     0.270482\n",
       "955       юрист     банкир       0.115927  0.478899     0.131748\n",
       "962        язык      горло       0.139113  0.642719     0.253619\n",
       "\n",
       "[498 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:04<00:00, 24372.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = SkipgramDataset(corpus, word2index)\n",
    "BATCH_SIZE = 512\n",
    "dataset_loader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_embedding = torch.nn.Embedding(num_embeddings=vocab_size, \n",
    "                                               embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.out_embedding = torch.nn.Linear(in_features=embedding_dim,\n",
    "                                             out_features=vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.in_embedding(x)\n",
    "        x = self.out_embedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "model = SkipGram(vocab_size=len(word2index), embedding_dim=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 13076])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0005)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████▉| 2982912/2983124 [13:11<00:00, 3769.99it/s, loss=7.11]\n",
      "Epoch 2: 100%|█████████▉| 2982912/2983124 [12:46<00:00, 3891.88it/s, loss=6.91]\n",
      "Epoch 3: 100%|█████████▉| 2982912/2983124 [10:41<00:00, 4649.17it/s, loss=6.84]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "losses = []\n",
    "\n",
    "for n_epoch in range(epochs):\n",
    "\n",
    "    try:\n",
    "\n",
    "        progress_bar = tqdm(total=len(dataset_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "        for x, y in dataset_loader:\n",
    "\n",
    "            optimizer.zero_grad()  #обнуляем градиенты\n",
    "            preds_proba = model(x) #прогоняем данные через модель\n",
    "            loss = criterion(preds_proba, y) #считаем значение функции потерь  \n",
    "            loss.backward() #считаем градиенты  \n",
    "            optimizer.step() #обновляем веса \n",
    "                        \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            progress_bar.set_postfix(loss=np.mean(losses[-100:]))\n",
    "\n",
    "            progress_bar.update(x.shape[0])\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        progress_bar.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.in_embedding.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(embedding_matrix, token2id, word1, word2):\n",
    "    \n",
    "    i1 = token2id[word1]\n",
    "    i2 = token2id[word2]\n",
    "    \n",
    "    v1, v2 = embedding_matrix[i1], embedding_matrix[i2]\n",
    "    \n",
    "    v1_n = v1.div(v1.norm(keepdim=True))\n",
    "    v2_n = v2.div(v2.norm(keepdim=True))\n",
    "    \n",
    "    similarity = torch.dot(v1_n, v2_n).item()\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Рубрика \"Удивляем\": в Якутске бродячие лошади. Обычно в городах бродячие кошки и собаки. А в Якутске лошади. Около города табуны на вольном выпасе, владельцы табунов не ограничивают перемещение своих лошадей. Поэтому довольно часто лошади в поисках еды приходят в город и гуляют по улицам и паркам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for index, row in simlex.iterrows():\n",
    "    if row['# Word1'] in word2index.keys() and row['Word2'] in word2index.keys():\n",
    "        simlex['my_res'][index] = cos_sim(embedding_matrix, word2index, row['# Word1'], row['Word2'])\n",
    "compare = simlex.loc[simlex['my_res']!='UNK']\n",
    "# нормализуем\n",
    "compare['Average Score'] = (compare['Average Score']-compare['Average Score'].min())/(compare['Average Score'].max()-compare['Average Score'].min())\n",
    "compare['my_res'] = (compare['my_res']-compare['my_res'].min())/(compare['my_res'].max()-compare['my_res'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbkazakova/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1366857100724108"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare['loss2'] = (compare['Average Score'] - compare['my_res'])**2\n",
    "MSE = compare['loss2'].mean()\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшилось!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
